[[accumulo-config]]
<<<
== Accumulo Configuration

=== Overview

The recommended Accumulo configuration for GeoWave requires several manual configuration steps but isolates the GeoWave
libraries in application specific classpath(s) reducing the possibility of dependency conflict issues. A single user for
all of geowave data or a user per data type are two of the many local configuration options just ensure each namespace
containing GeoWave tables is configured to pick up the geowave-accumulo.jar.

==== Procedure

. Create a user and namespace
. Grant the user ownership permissions on all tables created within the application namespace
. Create an application or data set specific classpath
. Configure all tables within the namespace to use the application classpath
. Configure GeoWave transaction support

[source, bash]
----
accumulo shell -u root
createuser geowave // <1>
createnamespace geowave
grant NameSpace.CREATE_TABLE -ns geowave -u geowave
config -s general.vfs.context.classpath.geowave=hdfs://NAME_NODE_FQDN:8020/accumulo/classpath/geowave/[^.].*.jar
config -ns geowave -s table.classpath.context=geowave
exit // <2>
# From the node with the GeoWave application server installed
java -cp "/usr/local/geowave/geoserver/webapps/geoserver/WEB-INF/lib/*" mil.nga.giat.geowave.vector.plugin.GeoWaveGTDataStore -z ZOOKEEPER_NODE:2181 -i accumulo -u root -p ROOT_PASSWORD -n geowave -m 20
----
<1> You'll be prompted for a password
<2> Done with Accumulo specific configs

These manual configuration steps have to be performed once after the first install of GeoWave. After the initial install you
may elect to do further user and namespace creation and configuring to provide isolation between groups and data sets

=== Versioning

It's of critical importance to ensure that the various GeoWave components are all the same version and that your client is of the same version
that was used to write the data.

==== Basic

The RPM packaged version of GeoWave puts a timestamp in the name so it's pretty easy to verify that you have a matched set of RPMs installed.
After an update of the components you must restart Accumulo to get vfs to download the new versions and this should keep everything synched.

.Compare version and timestamps of installed RPMs
[source, bash]
----
[spohnae@c1-master ~]$ rpm -qa | grep geowave
geowave-cdh5-ingest-0.8.4-201503252335.noarch
geowave-cdh5-core-0.8.4-201503252335.noarch
geowave-cdh5-accumulo-0.8.4-201503252335.noarch
geowave-cdh5-docs-0.8.4-201503252335.noarch
----

==== Advanced

When GeoWave tables are first accessed on a tablet server the vfs classpath tells Accumulo where to download the jar file from HDFS.
The jar file is copied into the local /tmp directory (the default general.vfs.cache.dir setting anyway) and loaded onto the classpath.
If there is ever doubt as to if these versions match you can use the commands below from a tablet server node to verify the version of
this artifact.

.Commit hash of the jar in HDFS
[source, bash]
----
sudo -u hdfs hadoop fs -cat /accumulo/classpath/geowave/geowave-accumulo-build.properties | grep scm.revision | sed s/project.scm.revision=//
----

.Compare with the versions downloaded locally
[source, bash]
----
sudo find /tmp -name "*geowave-accumulo.jar" -exec unzip -p {} build.properties  \; | grep scm.revision | sed s/project.scm.revision=//
----

.Example
[source, bash]
----
[spohnae@c1-node-03 ~]$ sudo -u hdfs hadoop fs -cat /accumulo/classpath/geowave/geowave-accumulo-build.properties | grep scm.revision | sed s/project.scm.revision=//
294ffb267e6691de3b9edc80e312bf5af7b2d23f <1>
[spohnae@c1-node-03 ~]$ sudo find /tmp -name "*geowave-accumulo.jar" -exec unzip -p {} build.properties  \; | grep scm.revision | sed s/project.scm.revision=//
294ffb267e6691de3b9edc80e312bf5af7b2d23f <2>
294ffb267e6691de3b9edc80e312bf5af7b2d23f <2>
25cf0f895bd0318ce4071a4680d6dd85e0b34f6b
----
<1> This is the version loaded into hdfs and should be present on all tablet servers once Accumulo has been restarted
<2> The find command will probably locate a number of different versions depending on how often you clean out /tmp.

There may be multiple versions copies present, one per JVM, the error scenario is when a tablet server is missing the correct iterator jar.
