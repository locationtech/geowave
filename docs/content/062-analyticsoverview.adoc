[[analytics-overview]]
== Analytics

=== Overview

Analytics embody algorithms tailored to geospatial data.  Most analytics leverage Hadoop MapReduce for bulk computation.
Results of analytic jobs consist of vector or raster data stored in GeoWave.  The analytics infrastructure provides tools to
build algorithms in Spark.  For example, a Kryo serializer/deserializer enables exchange of SimpleFeatures and the GeoWaveInputFormat
supplies data to the Hadoop RDD <1>.

[NOTE]
<1> GeoWaveInputFormat does not remove duplicate features that reference polygons spanning multiple index regions.

The following algorithms are provided.


[width="80%",cols="2,10",options="header"]
|=========================================================
|Name |Description
|KMeans++|
A K-Means implementation to find K centroids over the population of data.
A set of preliminary sampling iterations find an optimal value of K and the an initial set of K centroids.
The algorithm produces K centroids and their associated polygons.  Each polygon represents the concave hull
containing all features associated with a centroid.
The algorithm supports drilling down multiple levels. At each level, the set centroids are determined
from the set of features associated the same centroid from the previous level.
|KMeans Jump|
Uses KMeans++ over a range of k, choosing an optimal k using an information theoretic based measurement.
|KMeans Parallel|
Performs a KMeans Parallel Cluster
|DBScan|
The Density Based Scanner algorithm produces a set of convex polygons for each region meeting density criteria.
Density of region is measured by a minimum cardinality of enclosed features within a specified distance from each other.
|Nearest Neighbors|
A infrastructure component that produces all the neighbors of a feature within a specific distance.
|=========================================================

=== Building

First build the main project, specifying the dependency versions.

[source, bash]
----
export BUILD_ARGS="-Daccumulo.version=1.6.0-cdh5.1.4 -Dhadoop.version=2.6.0-cdh5.4.0 -Dgeotools.version=13.0 -Dgeoserver.version=2.7.0 -Dvendor.version=cdh5 -Daccumulo.api=1.6 -P cloudera"
git clone https://github.com/ngageoint/geowave.git
cd geowave
mvn install -Dfindbugs.skip=true -Dformatter.skip=true -DskipITs=true -DskipTests=true $BUILD_ARGS
----

Next, build the analytics tool framework.

[source, bash]
----
cd analytics/mapreduce
mvn package -P analytics-singlejar -Dfindbugs.skip=true -Dformatter.skip=true -DskipITs=true -DskipTests=true $BUILD_ARGS
----

=== Running

The 'singlejar' jar file is located in the analytics/mapreduce/target/munged.   The jar is executed by Yarn.

[source, bash]
----
yarn jar geowave-analytic-mapreduce-0.8.8-SNAPSHOT-analytics-singlejar.jar  -dbscan  -n rwgdrummer.gpx -u rwgdrummer -p rwgdrummer -z zookeeper-master:2181 -i accumulo -emn 2 -emx 6 -pd 1000 -pc mil.nga.giat.geowave.analytic.partitioner.OrthodromicDistancePartitioner -cms 10 -orc 4 -hdfsbase /user/rwgdrummer -b bdb4 -eit gpxpoint
----
