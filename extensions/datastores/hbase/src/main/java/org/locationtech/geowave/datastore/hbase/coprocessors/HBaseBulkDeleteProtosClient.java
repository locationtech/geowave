// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: HBaseBulkDeleteClient.proto

package org.locationtech.geowave.datastore.hbase.coprocessors.protobuf;

public final class HBaseBulkDeleteProtosClient
{
	private HBaseBulkDeleteProtosClient() {}

	public static void registerAllExtensions(
			org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistry registry ) {}

	public interface BulkDeleteRequestOrBuilder extends
			org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageOrBuilder
	{

		// required .BulkDeleteRequest.BulkDeleteType deleteType = 1;
		/**
		 * <code>required .BulkDeleteRequest.BulkDeleteType deleteType = 1;</code>
		 */
		boolean hasDeleteType();

		/**
		 * <code>required .BulkDeleteRequest.BulkDeleteType deleteType = 1;</code>
		 */
		org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType getDeleteType();

		// optional bytes rangeFilter = 2;
		/**
		 * <code>optional bytes rangeFilter = 2;</code>
		 */
		boolean hasRangeFilter();

		/**
		 * <code>optional bytes rangeFilter = 2;</code>
		 */
		org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getRangeFilter();

		// optional bytes filter = 3;
		/**
		 * <code>optional bytes filter = 3;</code>
		 */
		boolean hasFilter();

		/**
		 * <code>optional bytes filter = 3;</code>
		 */
		org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getFilter();

		// optional bytes model = 4;
		/**
		 * <code>optional bytes model = 4;</code>
		 */
		boolean hasModel();

		/**
		 * <code>optional bytes model = 4;</code>
		 */
		org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getModel();

		// optional bytes adapterIds = 5;
		/**
		 * <code>optional bytes adapterIds = 5;</code>
		 */
		boolean hasAdapterIds();

		/**
		 * <code>optional bytes adapterIds = 5;</code>
		 */
		org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getAdapterIds();

		// optional bytes numericIndexStrategyFilter = 6;
		/**
		 * <code>optional bytes numericIndexStrategyFilter = 6;</code>
		 */
		boolean hasNumericIndexStrategyFilter();

		/**
		 * <code>optional bytes numericIndexStrategyFilter = 6;</code>
		 */
		org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getNumericIndexStrategyFilter();

		// optional bool blockCaching = 7;
		/**
		 * <code>optional bool blockCaching = 7;</code>
		 */
		boolean hasBlockCaching();

		/**
		 * <code>optional bool blockCaching = 7;</code>
		 */
		boolean getBlockCaching();

		// optional int32 cacheSize = 8;
		/**
		 * <code>optional int32 cacheSize = 8;</code>
		 */
		boolean hasCacheSize();

		/**
		 * <code>optional int32 cacheSize = 8;</code>
		 */
		int getCacheSize();

		// required uint32 rowBatchSize = 9;
		/**
		 * <code>required uint32 rowBatchSize = 9;</code>
		 */
		boolean hasRowBatchSize();

		/**
		 * <code>required uint32 rowBatchSize = 9;</code>
		 */
		int getRowBatchSize();

		// optional uint64 timestamp = 10;
		/**
		 * <code>optional uint64 timestamp = 10;</code>
		 */
		boolean hasTimestamp();

		/**
		 * <code>optional uint64 timestamp = 10;</code>
		 */
		long getTimestamp();
	}

	/**
	 * Protobuf type {@code BulkDeleteRequest}
	 */
	public static final class BulkDeleteRequest extends
			org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage implements
			BulkDeleteRequestOrBuilder
	{
		// Use BulkDeleteRequest.newBuilder() to construct.
		private BulkDeleteRequest(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.Builder<?> builder ) {
			super(
					builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private BulkDeleteRequest(
				boolean noInit ) {
			this.unknownFields = org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet
					.getDefaultInstance();
		}

		private static final BulkDeleteRequest defaultInstance;

		public static BulkDeleteRequest getDefaultInstance() {
			return defaultInstance;
		}

		public BulkDeleteRequest getDefaultInstanceForType() {
			return defaultInstance;
		}

		private final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet getUnknownFields() {
			return this.unknownFields;
		}

		private BulkDeleteRequest(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
			initFields();
			int mutable_bitField0_ = 0;
			org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.Builder unknownFields = org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet
					.newBuilder();
			try {
				boolean done = false;
				while (!done) {
					int tag = input.readTag();
					switch (tag) {
						case 0:
							done = true;
							break;
						default: {
							if (!parseUnknownField(
									input,
									unknownFields,
									extensionRegistry,
									tag)) {
								done = true;
							}
							break;
						}
						case 8: {
							int rawValue = input.readEnum();
							org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType value = org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType
									.valueOf(rawValue);
							if (value == null) {
								unknownFields.mergeVarintField(
										1,
										rawValue);
							}
							else {
								bitField0_ |= 0x00000001;
								deleteType_ = value;
							}
							break;
						}
						case 18: {
							bitField0_ |= 0x00000002;
							rangeFilter_ = input.readBytes();
							break;
						}
						case 26: {
							bitField0_ |= 0x00000004;
							filter_ = input.readBytes();
							break;
						}
						case 34: {
							bitField0_ |= 0x00000008;
							model_ = input.readBytes();
							break;
						}
						case 42: {
							bitField0_ |= 0x00000010;
							adapterIds_ = input.readBytes();
							break;
						}
						case 50: {
							bitField0_ |= 0x00000020;
							numericIndexStrategyFilter_ = input.readBytes();
							break;
						}
						case 56: {
							bitField0_ |= 0x00000040;
							blockCaching_ = input.readBool();
							break;
						}
						case 64: {
							bitField0_ |= 0x00000080;
							cacheSize_ = input.readInt32();
							break;
						}
						case 72: {
							bitField0_ |= 0x00000100;
							rowBatchSize_ = input.readUInt32();
							break;
						}
						case 80: {
							bitField0_ |= 0x00000200;
							timestamp_ = input.readUInt64();
							break;
						}
					}
				}
			}
			catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
				throw e.setUnfinishedMessage(this);
			}
			catch (java.io.IOException e) {
				throw new org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			}
			finally {
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor getDescriptor() {
			return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.internal_static_BulkDeleteRequest_descriptor;
		}

		protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable() {
			return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.internal_static_BulkDeleteRequest_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.class,
							org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.Builder.class);
		}

		public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BulkDeleteRequest> PARSER = new org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractParser<BulkDeleteRequest>() {
			public BulkDeleteRequest parsePartialFrom(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
					org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
					throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
				return new BulkDeleteRequest(
						input,
						extensionRegistry);
			}
		};

		@java.lang.Override
		public org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BulkDeleteRequest> getParserForType() {
			return PARSER;
		}

		/**
		 * Protobuf enum {@code BulkDeleteRequest.BulkDeleteType}
		 */
		public enum BulkDeleteType
				implements
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ProtocolMessageEnum {
			/**
			 * <code>ROW = 0;</code>
			 */
			ROW(
					0,
					0),
			/**
			 * <code>FAMILY = 1;</code>
			 */
			FAMILY(
					1,
					1),
			/**
			 * <code>COLUMN = 2;</code>
			 */
			COLUMN(
					2,
					2),
			/**
			 * <code>VERSION = 3;</code>
			 */
			VERSION(
					3,
					3), ;

			/**
			 * <code>ROW = 0;</code>
			 */
			public static final int ROW_VALUE = 0;
			/**
			 * <code>FAMILY = 1;</code>
			 */
			public static final int FAMILY_VALUE = 1;
			/**
			 * <code>COLUMN = 2;</code>
			 */
			public static final int COLUMN_VALUE = 2;
			/**
			 * <code>VERSION = 3;</code>
			 */
			public static final int VERSION_VALUE = 3;

			public final int getNumber() {
				return value;
			}

			public static BulkDeleteType valueOf(
					int value ) {
				switch (value) {
					case 0:
						return ROW;
					case 1:
						return FAMILY;
					case 2:
						return COLUMN;
					case 3:
						return VERSION;
					default:
						return null;
				}
			}

			public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.EnumLiteMap<BulkDeleteType> internalGetValueMap() {
				return internalValueMap;
			}

			private static org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.EnumLiteMap<BulkDeleteType> internalValueMap = new org.apache.hadoop.hbase.shaded.com.google.protobuf.Internal.EnumLiteMap<BulkDeleteType>() {
				public BulkDeleteType findValueByNumber(
						int number ) {
					return BulkDeleteType.valueOf(number);
				}
			};

			public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor() {
				return getDescriptor().getValues().get(
						index);
			}

			public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType() {
				return getDescriptor();
			}

			public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.EnumDescriptor getDescriptor() {
				return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest
						.getDescriptor()
						.getEnumTypes()
						.get(
								0);
			}

			private static final BulkDeleteType[] VALUES = values();

			public static BulkDeleteType valueOf(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.EnumValueDescriptor desc ) {
				if (desc.getType() != getDescriptor()) {
					throw new java.lang.IllegalArgumentException(
							"EnumValueDescriptor is not for this type.");
				}
				return VALUES[desc.getIndex()];
			}

			private final int index;
			private final int value;

			private BulkDeleteType(
					int index,
					int value ) {
				this.index = index;
				this.value = value;
			}

			// @@protoc_insertion_point(enum_scope:BulkDeleteRequest.BulkDeleteType)
		}

		private int bitField0_;
		// required .BulkDeleteRequest.BulkDeleteType deleteType = 1;
		public static final int DELETETYPE_FIELD_NUMBER = 1;
		private org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType deleteType_;

		/**
		 * <code>required .BulkDeleteRequest.BulkDeleteType deleteType = 1;</code>
		 */
		public boolean hasDeleteType() {
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>required .BulkDeleteRequest.BulkDeleteType deleteType = 1;</code>
		 */
		public org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType getDeleteType() {
			return deleteType_;
		}

		// optional bytes rangeFilter = 2;
		public static final int RANGEFILTER_FIELD_NUMBER = 2;
		private org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString rangeFilter_;

		/**
		 * <code>optional bytes rangeFilter = 2;</code>
		 */
		public boolean hasRangeFilter() {
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional bytes rangeFilter = 2;</code>
		 */
		public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getRangeFilter() {
			return rangeFilter_;
		}

		// optional bytes filter = 3;
		public static final int FILTER_FIELD_NUMBER = 3;
		private org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString filter_;

		/**
		 * <code>optional bytes filter = 3;</code>
		 */
		public boolean hasFilter() {
			return ((bitField0_ & 0x00000004) == 0x00000004);
		}

		/**
		 * <code>optional bytes filter = 3;</code>
		 */
		public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getFilter() {
			return filter_;
		}

		// optional bytes model = 4;
		public static final int MODEL_FIELD_NUMBER = 4;
		private org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString model_;

		/**
		 * <code>optional bytes model = 4;</code>
		 */
		public boolean hasModel() {
			return ((bitField0_ & 0x00000008) == 0x00000008);
		}

		/**
		 * <code>optional bytes model = 4;</code>
		 */
		public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getModel() {
			return model_;
		}

		// optional bytes adapterIds = 5;
		public static final int ADAPTERIDS_FIELD_NUMBER = 5;
		private org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString adapterIds_;

		/**
		 * <code>optional bytes adapterIds = 5;</code>
		 */
		public boolean hasAdapterIds() {
			return ((bitField0_ & 0x00000010) == 0x00000010);
		}

		/**
		 * <code>optional bytes adapterIds = 5;</code>
		 */
		public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getAdapterIds() {
			return adapterIds_;
		}

		// optional bytes numericIndexStrategyFilter = 6;
		public static final int NUMERICINDEXSTRATEGYFILTER_FIELD_NUMBER = 6;
		private org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString numericIndexStrategyFilter_;

		/**
		 * <code>optional bytes numericIndexStrategyFilter = 6;</code>
		 */
		public boolean hasNumericIndexStrategyFilter() {
			return ((bitField0_ & 0x00000020) == 0x00000020);
		}

		/**
		 * <code>optional bytes numericIndexStrategyFilter = 6;</code>
		 */
		public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getNumericIndexStrategyFilter() {
			return numericIndexStrategyFilter_;
		}

		// optional bool blockCaching = 7;
		public static final int BLOCKCACHING_FIELD_NUMBER = 7;
		private boolean blockCaching_;

		/**
		 * <code>optional bool blockCaching = 7;</code>
		 */
		public boolean hasBlockCaching() {
			return ((bitField0_ & 0x00000040) == 0x00000040);
		}

		/**
		 * <code>optional bool blockCaching = 7;</code>
		 */
		public boolean getBlockCaching() {
			return blockCaching_;
		}

		// optional int32 cacheSize = 8;
		public static final int CACHESIZE_FIELD_NUMBER = 8;
		private int cacheSize_;

		/**
		 * <code>optional int32 cacheSize = 8;</code>
		 */
		public boolean hasCacheSize() {
			return ((bitField0_ & 0x00000080) == 0x00000080);
		}

		/**
		 * <code>optional int32 cacheSize = 8;</code>
		 */
		public int getCacheSize() {
			return cacheSize_;
		}

		// required uint32 rowBatchSize = 9;
		public static final int ROWBATCHSIZE_FIELD_NUMBER = 9;
		private int rowBatchSize_;

		/**
		 * <code>required uint32 rowBatchSize = 9;</code>
		 */
		public boolean hasRowBatchSize() {
			return ((bitField0_ & 0x00000100) == 0x00000100);
		}

		/**
		 * <code>required uint32 rowBatchSize = 9;</code>
		 */
		public int getRowBatchSize() {
			return rowBatchSize_;
		}

		// optional uint64 timestamp = 10;
		public static final int TIMESTAMP_FIELD_NUMBER = 10;
		private long timestamp_;

		/**
		 * <code>optional uint64 timestamp = 10;</code>
		 */
		public boolean hasTimestamp() {
			return ((bitField0_ & 0x00000200) == 0x00000200);
		}

		/**
		 * <code>optional uint64 timestamp = 10;</code>
		 */
		public long getTimestamp() {
			return timestamp_;
		}

		private void initFields() {
			deleteType_ = org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType.ROW;
			rangeFilter_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;
			filter_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;
			model_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;
			adapterIds_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;
			numericIndexStrategyFilter_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;
			blockCaching_ = false;
			cacheSize_ = 0;
			rowBatchSize_ = 0;
			timestamp_ = 0L;
		}

		private byte memoizedIsInitialized = -1;

		public final boolean isInitialized() {
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized != -1) return isInitialized == 1;

			if (!hasDeleteType()) {
				memoizedIsInitialized = 0;
				return false;
			}
			if (!hasRowBatchSize()) {
				memoizedIsInitialized = 0;
				return false;
			}
			memoizedIsInitialized = 1;
			return true;
		}

		public void writeTo(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream output )
				throws java.io.IOException {
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001)) {
				output.writeEnum(
						1,
						deleteType_.getNumber());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002)) {
				output.writeBytes(
						2,
						rangeFilter_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004)) {
				output.writeBytes(
						3,
						filter_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008)) {
				output.writeBytes(
						4,
						model_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010)) {
				output.writeBytes(
						5,
						adapterIds_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020)) {
				output.writeBytes(
						6,
						numericIndexStrategyFilter_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040)) {
				output.writeBool(
						7,
						blockCaching_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080)) {
				output.writeInt32(
						8,
						cacheSize_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100)) {
				output.writeUInt32(
						9,
						rowBatchSize_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200)) {
				output.writeUInt64(
						10,
						timestamp_);
			}
			getUnknownFields().writeTo(
					output);
		}

		private int memoizedSerializedSize = -1;

		public int getSerializedSize() {
			int size = memoizedSerializedSize;
			if (size != -1) return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeEnumSize(
						1,
						deleteType_.getNumber());
			}
			if (((bitField0_ & 0x00000002) == 0x00000002)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeBytesSize(
						2,
						rangeFilter_);
			}
			if (((bitField0_ & 0x00000004) == 0x00000004)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeBytesSize(
						3,
						filter_);
			}
			if (((bitField0_ & 0x00000008) == 0x00000008)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeBytesSize(
						4,
						model_);
			}
			if (((bitField0_ & 0x00000010) == 0x00000010)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeBytesSize(
						5,
						adapterIds_);
			}
			if (((bitField0_ & 0x00000020) == 0x00000020)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeBytesSize(
						6,
						numericIndexStrategyFilter_);
			}
			if (((bitField0_ & 0x00000040) == 0x00000040)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeBoolSize(
						7,
						blockCaching_);
			}
			if (((bitField0_ & 0x00000080) == 0x00000080)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeInt32Size(
						8,
						cacheSize_);
			}
			if (((bitField0_ & 0x00000100) == 0x00000100)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeUInt32Size(
						9,
						rowBatchSize_);
			}
			if (((bitField0_ & 0x00000200) == 0x00000200)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeUInt64Size(
						10,
						timestamp_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException {
			return super.writeReplace();
		}

		@java.lang.Override
		public boolean equals(
				final java.lang.Object obj ) {
			if (obj == this) {
				return true;
			}
			if (!(obj instanceof org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest)) {
				return super.equals(obj);
			}
			org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest other = (org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest) obj;

			boolean result = true;
			result = result && (hasDeleteType() == other.hasDeleteType());
			if (hasDeleteType()) {
				result = result && (getDeleteType() == other.getDeleteType());
			}
			result = result && (hasRangeFilter() == other.hasRangeFilter());
			if (hasRangeFilter()) {
				result = result && getRangeFilter().equals(
						other.getRangeFilter());
			}
			result = result && (hasFilter() == other.hasFilter());
			if (hasFilter()) {
				result = result && getFilter().equals(
						other.getFilter());
			}
			result = result && (hasModel() == other.hasModel());
			if (hasModel()) {
				result = result && getModel().equals(
						other.getModel());
			}
			result = result && (hasAdapterIds() == other.hasAdapterIds());
			if (hasAdapterIds()) {
				result = result && getAdapterIds().equals(
						other.getAdapterIds());
			}
			result = result && (hasNumericIndexStrategyFilter() == other.hasNumericIndexStrategyFilter());
			if (hasNumericIndexStrategyFilter()) {
				result = result && getNumericIndexStrategyFilter().equals(
						other.getNumericIndexStrategyFilter());
			}
			result = result && (hasBlockCaching() == other.hasBlockCaching());
			if (hasBlockCaching()) {
				result = result && (getBlockCaching() == other.getBlockCaching());
			}
			result = result && (hasCacheSize() == other.hasCacheSize());
			if (hasCacheSize()) {
				result = result && (getCacheSize() == other.getCacheSize());
			}
			result = result && (hasRowBatchSize() == other.hasRowBatchSize());
			if (hasRowBatchSize()) {
				result = result && (getRowBatchSize() == other.getRowBatchSize());
			}
			result = result && (hasTimestamp() == other.hasTimestamp());
			if (hasTimestamp()) {
				result = result && (getTimestamp() == other.getTimestamp());
			}
			result = result && getUnknownFields().equals(
					other.getUnknownFields());
			return result;
		}

		private int memoizedHashCode = 0;

		@java.lang.Override
		public int hashCode() {
			if (memoizedHashCode != 0) {
				return memoizedHashCode;
			}
			int hash = 41;
			hash = (19 * hash) + getDescriptorForType().hashCode();
			if (hasDeleteType()) {
				hash = (37 * hash) + DELETETYPE_FIELD_NUMBER;
				hash = (53 * hash) + hashEnum(getDeleteType());
			}
			if (hasRangeFilter()) {
				hash = (37 * hash) + RANGEFILTER_FIELD_NUMBER;
				hash = (53 * hash) + getRangeFilter().hashCode();
			}
			if (hasFilter()) {
				hash = (37 * hash) + FILTER_FIELD_NUMBER;
				hash = (53 * hash) + getFilter().hashCode();
			}
			if (hasModel()) {
				hash = (37 * hash) + MODEL_FIELD_NUMBER;
				hash = (53 * hash) + getModel().hashCode();
			}
			if (hasAdapterIds()) {
				hash = (37 * hash) + ADAPTERIDS_FIELD_NUMBER;
				hash = (53 * hash) + getAdapterIds().hashCode();
			}
			if (hasNumericIndexStrategyFilter()) {
				hash = (37 * hash) + NUMERICINDEXSTRATEGYFILTER_FIELD_NUMBER;
				hash = (53 * hash) + getNumericIndexStrategyFilter().hashCode();
			}
			if (hasBlockCaching()) {
				hash = (37 * hash) + BLOCKCACHING_FIELD_NUMBER;
				hash = (53 * hash) + hashBoolean(getBlockCaching());
			}
			if (hasCacheSize()) {
				hash = (37 * hash) + CACHESIZE_FIELD_NUMBER;
				hash = (53 * hash) + getCacheSize();
			}
			if (hasRowBatchSize()) {
				hash = (37 * hash) + ROWBATCHSIZE_FIELD_NUMBER;
				hash = (53 * hash) + getRowBatchSize();
			}
			if (hasTimestamp()) {
				hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
				hash = (53 * hash) + hashLong(getTimestamp());
			}
			hash = (29 * hash) + getUnknownFields().hashCode();
			memoizedHashCode = hash;
			return hash;
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parseFrom(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data )
				throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
			return PARSER.parseFrom(data);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parseFrom(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
			return PARSER.parseFrom(
					data,
					extensionRegistry);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parseFrom(
				byte[] data )
				throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
			return PARSER.parseFrom(data);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parseFrom(
				byte[] data,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
			return PARSER.parseFrom(
					data,
					extensionRegistry);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parseFrom(
				java.io.InputStream input )
				throws java.io.IOException {
			return PARSER.parseFrom(input);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parseFrom(
				java.io.InputStream input,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws java.io.IOException {
			return PARSER.parseFrom(
					input,
					extensionRegistry);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parseDelimitedFrom(
				java.io.InputStream input )
				throws java.io.IOException {
			return PARSER.parseDelimitedFrom(input);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parseDelimitedFrom(
				java.io.InputStream input,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws java.io.IOException {
			return PARSER.parseDelimitedFrom(
					input,
					extensionRegistry);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parseFrom(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input )
				throws java.io.IOException {
			return PARSER.parseFrom(input);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parseFrom(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws java.io.IOException {
			return PARSER.parseFrom(
					input,
					extensionRegistry);
		}

		public static Builder newBuilder() {
			return Builder.create();
		}

		public Builder newBuilderForType() {
			return newBuilder();
		}

		public static Builder newBuilder(
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest prototype ) {
			return newBuilder().mergeFrom(
					prototype);
		}

		public Builder toBuilder() {
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.BuilderParent parent ) {
			Builder builder = new Builder(
					parent);
			return builder;
		}

		/**
		 * Protobuf type {@code BulkDeleteRequest}
		 */
		public static final class Builder extends
				org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequestOrBuilder
		{
			public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor getDescriptor() {
				return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.internal_static_BulkDeleteRequest_descriptor;
			}

			protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable() {
				return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.internal_static_BulkDeleteRequest_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.class,
								org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.Builder.class);
			}

			// Construct using
			// org.locationtech.geowave.datastore.hbase.query.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.newBuilder()
			private Builder() {
				maybeForceBuilderInitialization();
			}

			private Builder(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.BuilderParent parent ) {
				super(
						parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization() {
				if (org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {}
			}

			private static Builder create() {
				return new Builder();
			}

			public Builder clear() {
				super.clear();
				deleteType_ = org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType.ROW;
				bitField0_ = (bitField0_ & ~0x00000001);
				rangeFilter_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000002);
				filter_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000004);
				model_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000008);
				adapterIds_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000010);
				numericIndexStrategyFilter_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;
				bitField0_ = (bitField0_ & ~0x00000020);
				blockCaching_ = false;
				bitField0_ = (bitField0_ & ~0x00000040);
				cacheSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000080);
				rowBatchSize_ = 0;
				bitField0_ = (bitField0_ & ~0x00000100);
				timestamp_ = 0L;
				bitField0_ = (bitField0_ & ~0x00000200);
				return this;
			}

			public Builder clone() {
				return create().mergeFrom(
						buildPartial());
			}

			public org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
				return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.internal_static_BulkDeleteRequest_descriptor;
			}

			public org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest getDefaultInstanceForType() {
				return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest
						.getDefaultInstance();
			}

			public org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest build() {
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest result = buildPartial();
				if (!result.isInitialized()) {
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			public org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest buildPartial() {
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest result = new org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest(
						this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
					to_bitField0_ |= 0x00000001;
				}
				result.deleteType_ = deleteType_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
					to_bitField0_ |= 0x00000002;
				}
				result.rangeFilter_ = rangeFilter_;
				if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
					to_bitField0_ |= 0x00000004;
				}
				result.filter_ = filter_;
				if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
					to_bitField0_ |= 0x00000008;
				}
				result.model_ = model_;
				if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
					to_bitField0_ |= 0x00000010;
				}
				result.adapterIds_ = adapterIds_;
				if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
					to_bitField0_ |= 0x00000020;
				}
				result.numericIndexStrategyFilter_ = numericIndexStrategyFilter_;
				if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
					to_bitField0_ |= 0x00000040;
				}
				result.blockCaching_ = blockCaching_;
				if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
					to_bitField0_ |= 0x00000080;
				}
				result.cacheSize_ = cacheSize_;
				if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
					to_bitField0_ |= 0x00000100;
				}
				result.rowBatchSize_ = rowBatchSize_;
				if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
					to_bitField0_ |= 0x00000200;
				}
				result.timestamp_ = timestamp_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			public Builder mergeFrom(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.Message other ) {
				if (other instanceof org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest) {
					return mergeFrom((org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest) other);
				}
				else {
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(
					org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest other ) {
				if (other == org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest
						.getDefaultInstance()) return this;
				if (other.hasDeleteType()) {
					setDeleteType(other.getDeleteType());
				}
				if (other.hasRangeFilter()) {
					setRangeFilter(other.getRangeFilter());
				}
				if (other.hasFilter()) {
					setFilter(other.getFilter());
				}
				if (other.hasModel()) {
					setModel(other.getModel());
				}
				if (other.hasAdapterIds()) {
					setAdapterIds(other.getAdapterIds());
				}
				if (other.hasNumericIndexStrategyFilter()) {
					setNumericIndexStrategyFilter(other.getNumericIndexStrategyFilter());
				}
				if (other.hasBlockCaching()) {
					setBlockCaching(other.getBlockCaching());
				}
				if (other.hasCacheSize()) {
					setCacheSize(other.getCacheSize());
				}
				if (other.hasRowBatchSize()) {
					setRowBatchSize(other.getRowBatchSize());
				}
				if (other.hasTimestamp()) {
					setTimestamp(other.getTimestamp());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			public final boolean isInitialized() {
				if (!hasDeleteType()) {

					return false;
				}
				if (!hasRowBatchSize()) {

					return false;
				}
				return true;
			}

			public Builder mergeFrom(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
					org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
					throws java.io.IOException {
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest parsedMessage = null;
				try {
					parsedMessage = PARSER.parsePartialFrom(
							input,
							extensionRegistry);
				}
				catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
					parsedMessage = (org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest) e
							.getUnfinishedMessage();
					throw e;
				}
				finally {
					if (parsedMessage != null) {
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			// required .BulkDeleteRequest.BulkDeleteType deleteType = 1;
			private org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType deleteType_ = org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType.ROW;

			/**
			 * <code>required .BulkDeleteRequest.BulkDeleteType deleteType = 1;</code>
			 */
			public boolean hasDeleteType() {
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>required .BulkDeleteRequest.BulkDeleteType deleteType = 1;</code>
			 */
			public org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType getDeleteType() {
				return deleteType_;
			}

			/**
			 * <code>required .BulkDeleteRequest.BulkDeleteType deleteType = 1;</code>
			 */
			public Builder setDeleteType(
					org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType value ) {
				if (value == null) {
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000001;
				deleteType_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>required .BulkDeleteRequest.BulkDeleteType deleteType = 1;</code>
			 */
			public Builder clearDeleteType() {
				bitField0_ = (bitField0_ & ~0x00000001);
				deleteType_ = org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest.BulkDeleteType.ROW;
				onChanged();
				return this;
			}

			// optional bytes rangeFilter = 2;
			private org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString rangeFilter_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;

			/**
			 * <code>optional bytes rangeFilter = 2;</code>
			 */
			public boolean hasRangeFilter() {
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional bytes rangeFilter = 2;</code>
			 */
			public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getRangeFilter() {
				return rangeFilter_;
			}

			/**
			 * <code>optional bytes rangeFilter = 2;</code>
			 */
			public Builder setRangeFilter(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString value ) {
				if (value == null) {
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000002;
				rangeFilter_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bytes rangeFilter = 2;</code>
			 */
			public Builder clearRangeFilter() {
				bitField0_ = (bitField0_ & ~0x00000002);
				rangeFilter_ = getDefaultInstance().getRangeFilter();
				onChanged();
				return this;
			}

			// optional bytes filter = 3;
			private org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString filter_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;

			/**
			 * <code>optional bytes filter = 3;</code>
			 */
			public boolean hasFilter() {
				return ((bitField0_ & 0x00000004) == 0x00000004);
			}

			/**
			 * <code>optional bytes filter = 3;</code>
			 */
			public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getFilter() {
				return filter_;
			}

			/**
			 * <code>optional bytes filter = 3;</code>
			 */
			public Builder setFilter(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString value ) {
				if (value == null) {
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000004;
				filter_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bytes filter = 3;</code>
			 */
			public Builder clearFilter() {
				bitField0_ = (bitField0_ & ~0x00000004);
				filter_ = getDefaultInstance().getFilter();
				onChanged();
				return this;
			}

			// optional bytes model = 4;
			private org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString model_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;

			/**
			 * <code>optional bytes model = 4;</code>
			 */
			public boolean hasModel() {
				return ((bitField0_ & 0x00000008) == 0x00000008);
			}

			/**
			 * <code>optional bytes model = 4;</code>
			 */
			public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getModel() {
				return model_;
			}

			/**
			 * <code>optional bytes model = 4;</code>
			 */
			public Builder setModel(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString value ) {
				if (value == null) {
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000008;
				model_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bytes model = 4;</code>
			 */
			public Builder clearModel() {
				bitField0_ = (bitField0_ & ~0x00000008);
				model_ = getDefaultInstance().getModel();
				onChanged();
				return this;
			}

			// optional bytes adapterIds = 5;
			private org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString adapterIds_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;

			/**
			 * <code>optional bytes adapterIds = 5;</code>
			 */
			public boolean hasAdapterIds() {
				return ((bitField0_ & 0x00000010) == 0x00000010);
			}

			/**
			 * <code>optional bytes adapterIds = 5;</code>
			 */
			public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getAdapterIds() {
				return adapterIds_;
			}

			/**
			 * <code>optional bytes adapterIds = 5;</code>
			 */
			public Builder setAdapterIds(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString value ) {
				if (value == null) {
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000010;
				adapterIds_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bytes adapterIds = 5;</code>
			 */
			public Builder clearAdapterIds() {
				bitField0_ = (bitField0_ & ~0x00000010);
				adapterIds_ = getDefaultInstance().getAdapterIds();
				onChanged();
				return this;
			}

			// optional bytes numericIndexStrategyFilter = 6;
			private org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString numericIndexStrategyFilter_ = org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString.EMPTY;

			/**
			 * <code>optional bytes numericIndexStrategyFilter = 6;</code>
			 */
			public boolean hasNumericIndexStrategyFilter() {
				return ((bitField0_ & 0x00000020) == 0x00000020);
			}

			/**
			 * <code>optional bytes numericIndexStrategyFilter = 6;</code>
			 */
			public org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString getNumericIndexStrategyFilter() {
				return numericIndexStrategyFilter_;
			}

			/**
			 * <code>optional bytes numericIndexStrategyFilter = 6;</code>
			 */
			public Builder setNumericIndexStrategyFilter(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString value ) {
				if (value == null) {
					throw new NullPointerException();
				}
				bitField0_ |= 0x00000020;
				numericIndexStrategyFilter_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bytes numericIndexStrategyFilter = 6;</code>
			 */
			public Builder clearNumericIndexStrategyFilter() {
				bitField0_ = (bitField0_ & ~0x00000020);
				numericIndexStrategyFilter_ = getDefaultInstance().getNumericIndexStrategyFilter();
				onChanged();
				return this;
			}

			// optional bool blockCaching = 7;
			private boolean blockCaching_;

			/**
			 * <code>optional bool blockCaching = 7;</code>
			 */
			public boolean hasBlockCaching() {
				return ((bitField0_ & 0x00000040) == 0x00000040);
			}

			/**
			 * <code>optional bool blockCaching = 7;</code>
			 */
			public boolean getBlockCaching() {
				return blockCaching_;
			}

			/**
			 * <code>optional bool blockCaching = 7;</code>
			 */
			public Builder setBlockCaching(
					boolean value ) {
				bitField0_ |= 0x00000040;
				blockCaching_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional bool blockCaching = 7;</code>
			 */
			public Builder clearBlockCaching() {
				bitField0_ = (bitField0_ & ~0x00000040);
				blockCaching_ = false;
				onChanged();
				return this;
			}

			// optional int32 cacheSize = 8;
			private int cacheSize_;

			/**
			 * <code>optional int32 cacheSize = 8;</code>
			 */
			public boolean hasCacheSize() {
				return ((bitField0_ & 0x00000080) == 0x00000080);
			}

			/**
			 * <code>optional int32 cacheSize = 8;</code>
			 */
			public int getCacheSize() {
				return cacheSize_;
			}

			/**
			 * <code>optional int32 cacheSize = 8;</code>
			 */
			public Builder setCacheSize(
					int value ) {
				bitField0_ |= 0x00000080;
				cacheSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional int32 cacheSize = 8;</code>
			 */
			public Builder clearCacheSize() {
				bitField0_ = (bitField0_ & ~0x00000080);
				cacheSize_ = 0;
				onChanged();
				return this;
			}

			// required uint32 rowBatchSize = 9;
			private int rowBatchSize_;

			/**
			 * <code>required uint32 rowBatchSize = 9;</code>
			 */
			public boolean hasRowBatchSize() {
				return ((bitField0_ & 0x00000100) == 0x00000100);
			}

			/**
			 * <code>required uint32 rowBatchSize = 9;</code>
			 */
			public int getRowBatchSize() {
				return rowBatchSize_;
			}

			/**
			 * <code>required uint32 rowBatchSize = 9;</code>
			 */
			public Builder setRowBatchSize(
					int value ) {
				bitField0_ |= 0x00000100;
				rowBatchSize_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>required uint32 rowBatchSize = 9;</code>
			 */
			public Builder clearRowBatchSize() {
				bitField0_ = (bitField0_ & ~0x00000100);
				rowBatchSize_ = 0;
				onChanged();
				return this;
			}

			// optional uint64 timestamp = 10;
			private long timestamp_;

			/**
			 * <code>optional uint64 timestamp = 10;</code>
			 */
			public boolean hasTimestamp() {
				return ((bitField0_ & 0x00000200) == 0x00000200);
			}

			/**
			 * <code>optional uint64 timestamp = 10;</code>
			 */
			public long getTimestamp() {
				return timestamp_;
			}

			/**
			 * <code>optional uint64 timestamp = 10;</code>
			 */
			public Builder setTimestamp(
					long value ) {
				bitField0_ |= 0x00000200;
				timestamp_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint64 timestamp = 10;</code>
			 */
			public Builder clearTimestamp() {
				bitField0_ = (bitField0_ & ~0x00000200);
				timestamp_ = 0L;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:BulkDeleteRequest)
		}

		static {
			defaultInstance = new BulkDeleteRequest(
					true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:BulkDeleteRequest)
	}

	public interface BulkDeleteResponseOrBuilder extends
			org.apache.hadoop.hbase.shaded.com.google.protobuf.MessageOrBuilder
	{

		// required uint64 rowsDeleted = 1;
		/**
		 * <code>required uint64 rowsDeleted = 1;</code>
		 */
		boolean hasRowsDeleted();

		/**
		 * <code>required uint64 rowsDeleted = 1;</code>
		 */
		long getRowsDeleted();

		// optional uint64 versionsDeleted = 2;
		/**
		 * <code>optional uint64 versionsDeleted = 2;</code>
		 */
		boolean hasVersionsDeleted();

		/**
		 * <code>optional uint64 versionsDeleted = 2;</code>
		 */
		long getVersionsDeleted();
	}

	/**
	 * Protobuf type {@code BulkDeleteResponse}
	 */
	public static final class BulkDeleteResponse extends
			org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage implements
			BulkDeleteResponseOrBuilder
	{
		// Use BulkDeleteResponse.newBuilder() to construct.
		private BulkDeleteResponse(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.Builder<?> builder ) {
			super(
					builder);
			this.unknownFields = builder.getUnknownFields();
		}

		private BulkDeleteResponse(
				boolean noInit ) {
			this.unknownFields = org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet
					.getDefaultInstance();
		}

		private static final BulkDeleteResponse defaultInstance;

		public static BulkDeleteResponse getDefaultInstance() {
			return defaultInstance;
		}

		public BulkDeleteResponse getDefaultInstanceForType() {
			return defaultInstance;
		}

		private final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet unknownFields;

		@java.lang.Override
		public final org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet getUnknownFields() {
			return this.unknownFields;
		}

		private BulkDeleteResponse(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
			initFields();
			int mutable_bitField0_ = 0;
			org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet.Builder unknownFields = org.apache.hadoop.hbase.shaded.com.google.protobuf.UnknownFieldSet
					.newBuilder();
			try {
				boolean done = false;
				while (!done) {
					int tag = input.readTag();
					switch (tag) {
						case 0:
							done = true;
							break;
						default: {
							if (!parseUnknownField(
									input,
									unknownFields,
									extensionRegistry,
									tag)) {
								done = true;
							}
							break;
						}
						case 8: {
							bitField0_ |= 0x00000001;
							rowsDeleted_ = input.readUInt64();
							break;
						}
						case 16: {
							bitField0_ |= 0x00000002;
							versionsDeleted_ = input.readUInt64();
							break;
						}
					}
				}
			}
			catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
				throw e.setUnfinishedMessage(this);
			}
			catch (java.io.IOException e) {
				throw new org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException(
						e.getMessage()).setUnfinishedMessage(this);
			}
			finally {
				this.unknownFields = unknownFields.build();
				makeExtensionsImmutable();
			}
		}

		public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor getDescriptor() {
			return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.internal_static_BulkDeleteResponse_descriptor;
		}

		protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable() {
			return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.internal_static_BulkDeleteResponse_fieldAccessorTable
					.ensureFieldAccessorsInitialized(
							org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse.class,
							org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse.Builder.class);
		}

		public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BulkDeleteResponse> PARSER = new org.apache.hadoop.hbase.shaded.com.google.protobuf.AbstractParser<BulkDeleteResponse>() {
			public BulkDeleteResponse parsePartialFrom(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
					org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
					throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
				return new BulkDeleteResponse(
						input,
						extensionRegistry);
			}
		};

		@java.lang.Override
		public org.apache.hadoop.hbase.shaded.com.google.protobuf.Parser<BulkDeleteResponse> getParserForType() {
			return PARSER;
		}

		private int bitField0_;
		// required uint64 rowsDeleted = 1;
		public static final int ROWSDELETED_FIELD_NUMBER = 1;
		private long rowsDeleted_;

		/**
		 * <code>required uint64 rowsDeleted = 1;</code>
		 */
		public boolean hasRowsDeleted() {
			return ((bitField0_ & 0x00000001) == 0x00000001);
		}

		/**
		 * <code>required uint64 rowsDeleted = 1;</code>
		 */
		public long getRowsDeleted() {
			return rowsDeleted_;
		}

		// optional uint64 versionsDeleted = 2;
		public static final int VERSIONSDELETED_FIELD_NUMBER = 2;
		private long versionsDeleted_;

		/**
		 * <code>optional uint64 versionsDeleted = 2;</code>
		 */
		public boolean hasVersionsDeleted() {
			return ((bitField0_ & 0x00000002) == 0x00000002);
		}

		/**
		 * <code>optional uint64 versionsDeleted = 2;</code>
		 */
		public long getVersionsDeleted() {
			return versionsDeleted_;
		}

		private void initFields() {
			rowsDeleted_ = 0L;
			versionsDeleted_ = 0L;
		}

		private byte memoizedIsInitialized = -1;

		public final boolean isInitialized() {
			byte isInitialized = memoizedIsInitialized;
			if (isInitialized != -1) return isInitialized == 1;

			if (!hasRowsDeleted()) {
				memoizedIsInitialized = 0;
				return false;
			}
			memoizedIsInitialized = 1;
			return true;
		}

		public void writeTo(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream output )
				throws java.io.IOException {
			getSerializedSize();
			if (((bitField0_ & 0x00000001) == 0x00000001)) {
				output.writeUInt64(
						1,
						rowsDeleted_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002)) {
				output.writeUInt64(
						2,
						versionsDeleted_);
			}
			getUnknownFields().writeTo(
					output);
		}

		private int memoizedSerializedSize = -1;

		public int getSerializedSize() {
			int size = memoizedSerializedSize;
			if (size != -1) return size;

			size = 0;
			if (((bitField0_ & 0x00000001) == 0x00000001)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeUInt64Size(
						1,
						rowsDeleted_);
			}
			if (((bitField0_ & 0x00000002) == 0x00000002)) {
				size += org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedOutputStream.computeUInt64Size(
						2,
						versionsDeleted_);
			}
			size += getUnknownFields().getSerializedSize();
			memoizedSerializedSize = size;
			return size;
		}

		private static final long serialVersionUID = 0L;

		@java.lang.Override
		protected java.lang.Object writeReplace()
				throws java.io.ObjectStreamException {
			return super.writeReplace();
		}

		@java.lang.Override
		public boolean equals(
				final java.lang.Object obj ) {
			if (obj == this) {
				return true;
			}
			if (!(obj instanceof org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse)) {
				return super.equals(obj);
			}
			org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse other = (org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse) obj;

			boolean result = true;
			result = result && (hasRowsDeleted() == other.hasRowsDeleted());
			if (hasRowsDeleted()) {
				result = result && (getRowsDeleted() == other.getRowsDeleted());
			}
			result = result && (hasVersionsDeleted() == other.hasVersionsDeleted());
			if (hasVersionsDeleted()) {
				result = result && (getVersionsDeleted() == other.getVersionsDeleted());
			}
			result = result && getUnknownFields().equals(
					other.getUnknownFields());
			return result;
		}

		private int memoizedHashCode = 0;

		@java.lang.Override
		public int hashCode() {
			if (memoizedHashCode != 0) {
				return memoizedHashCode;
			}
			int hash = 41;
			hash = (19 * hash) + getDescriptorForType().hashCode();
			if (hasRowsDeleted()) {
				hash = (37 * hash) + ROWSDELETED_FIELD_NUMBER;
				hash = (53 * hash) + hashLong(getRowsDeleted());
			}
			if (hasVersionsDeleted()) {
				hash = (37 * hash) + VERSIONSDELETED_FIELD_NUMBER;
				hash = (53 * hash) + hashLong(getVersionsDeleted());
			}
			hash = (29 * hash) + getUnknownFields().hashCode();
			memoizedHashCode = hash;
			return hash;
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parseFrom(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data )
				throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
			return PARSER.parseFrom(data);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parseFrom(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ByteString data,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
			return PARSER.parseFrom(
					data,
					extensionRegistry);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parseFrom(
				byte[] data )
				throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
			return PARSER.parseFrom(data);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parseFrom(
				byte[] data,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException {
			return PARSER.parseFrom(
					data,
					extensionRegistry);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parseFrom(
				java.io.InputStream input )
				throws java.io.IOException {
			return PARSER.parseFrom(input);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parseFrom(
				java.io.InputStream input,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws java.io.IOException {
			return PARSER.parseFrom(
					input,
					extensionRegistry);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parseDelimitedFrom(
				java.io.InputStream input )
				throws java.io.IOException {
			return PARSER.parseDelimitedFrom(input);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parseDelimitedFrom(
				java.io.InputStream input,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws java.io.IOException {
			return PARSER.parseDelimitedFrom(
					input,
					extensionRegistry);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parseFrom(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input )
				throws java.io.IOException {
			return PARSER.parseFrom(input);
		}

		public static org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parseFrom(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
				throws java.io.IOException {
			return PARSER.parseFrom(
					input,
					extensionRegistry);
		}

		public static Builder newBuilder() {
			return Builder.create();
		}

		public Builder newBuilderForType() {
			return newBuilder();
		}

		public static Builder newBuilder(
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse prototype ) {
			return newBuilder().mergeFrom(
					prototype);
		}

		public Builder toBuilder() {
			return newBuilder(this);
		}

		@java.lang.Override
		protected Builder newBuilderForType(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.BuilderParent parent ) {
			Builder builder = new Builder(
					parent);
			return builder;
		}

		/**
		 * Protobuf type {@code BulkDeleteResponse}
		 */
		public static final class Builder extends
				org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.Builder<Builder> implements
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponseOrBuilder
		{
			public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor getDescriptor() {
				return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.internal_static_BulkDeleteResponse_descriptor;
			}

			protected org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable() {
				return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.internal_static_BulkDeleteResponse_fieldAccessorTable
						.ensureFieldAccessorsInitialized(
								org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse.class,
								org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse.Builder.class);
			}

			// Construct using
			// org.locationtech.geowave.datastore.hbase.query.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse.newBuilder()
			private Builder() {
				maybeForceBuilderInitialization();
			}

			private Builder(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.BuilderParent parent ) {
				super(
						parent);
				maybeForceBuilderInitialization();
			}

			private void maybeForceBuilderInitialization() {
				if (org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {}
			}

			private static Builder create() {
				return new Builder();
			}

			public Builder clear() {
				super.clear();
				rowsDeleted_ = 0L;
				bitField0_ = (bitField0_ & ~0x00000001);
				versionsDeleted_ = 0L;
				bitField0_ = (bitField0_ & ~0x00000002);
				return this;
			}

			public Builder clone() {
				return create().mergeFrom(
						buildPartial());
			}

			public org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
				return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.internal_static_BulkDeleteResponse_descriptor;
			}

			public org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse getDefaultInstanceForType() {
				return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse
						.getDefaultInstance();
			}

			public org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse build() {
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse result = buildPartial();
				if (!result.isInitialized()) {
					throw newUninitializedMessageException(result);
				}
				return result;
			}

			public org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse buildPartial() {
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse result = new org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse(
						this);
				int from_bitField0_ = bitField0_;
				int to_bitField0_ = 0;
				if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
					to_bitField0_ |= 0x00000001;
				}
				result.rowsDeleted_ = rowsDeleted_;
				if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
					to_bitField0_ |= 0x00000002;
				}
				result.versionsDeleted_ = versionsDeleted_;
				result.bitField0_ = to_bitField0_;
				onBuilt();
				return result;
			}

			public Builder mergeFrom(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.Message other ) {
				if (other instanceof org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse) {
					return mergeFrom((org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse) other);
				}
				else {
					super.mergeFrom(other);
					return this;
				}
			}

			public Builder mergeFrom(
					org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse other ) {
				if (other == org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse
						.getDefaultInstance()) return this;
				if (other.hasRowsDeleted()) {
					setRowsDeleted(other.getRowsDeleted());
				}
				if (other.hasVersionsDeleted()) {
					setVersionsDeleted(other.getVersionsDeleted());
				}
				this.mergeUnknownFields(other.getUnknownFields());
				return this;
			}

			public final boolean isInitialized() {
				if (!hasRowsDeleted()) {

					return false;
				}
				return true;
			}

			public Builder mergeFrom(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.CodedInputStream input,
					org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistryLite extensionRegistry )
					throws java.io.IOException {
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse parsedMessage = null;
				try {
					parsedMessage = PARSER.parsePartialFrom(
							input,
							extensionRegistry);
				}
				catch (org.apache.hadoop.hbase.shaded.com.google.protobuf.InvalidProtocolBufferException e) {
					parsedMessage = (org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse) e
							.getUnfinishedMessage();
					throw e;
				}
				finally {
					if (parsedMessage != null) {
						mergeFrom(parsedMessage);
					}
				}
				return this;
			}

			private int bitField0_;

			// required uint64 rowsDeleted = 1;
			private long rowsDeleted_;

			/**
			 * <code>required uint64 rowsDeleted = 1;</code>
			 */
			public boolean hasRowsDeleted() {
				return ((bitField0_ & 0x00000001) == 0x00000001);
			}

			/**
			 * <code>required uint64 rowsDeleted = 1;</code>
			 */
			public long getRowsDeleted() {
				return rowsDeleted_;
			}

			/**
			 * <code>required uint64 rowsDeleted = 1;</code>
			 */
			public Builder setRowsDeleted(
					long value ) {
				bitField0_ |= 0x00000001;
				rowsDeleted_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>required uint64 rowsDeleted = 1;</code>
			 */
			public Builder clearRowsDeleted() {
				bitField0_ = (bitField0_ & ~0x00000001);
				rowsDeleted_ = 0L;
				onChanged();
				return this;
			}

			// optional uint64 versionsDeleted = 2;
			private long versionsDeleted_;

			/**
			 * <code>optional uint64 versionsDeleted = 2;</code>
			 */
			public boolean hasVersionsDeleted() {
				return ((bitField0_ & 0x00000002) == 0x00000002);
			}

			/**
			 * <code>optional uint64 versionsDeleted = 2;</code>
			 */
			public long getVersionsDeleted() {
				return versionsDeleted_;
			}

			/**
			 * <code>optional uint64 versionsDeleted = 2;</code>
			 */
			public Builder setVersionsDeleted(
					long value ) {
				bitField0_ |= 0x00000002;
				versionsDeleted_ = value;
				onChanged();
				return this;
			}

			/**
			 * <code>optional uint64 versionsDeleted = 2;</code>
			 */
			public Builder clearVersionsDeleted() {
				bitField0_ = (bitField0_ & ~0x00000002);
				versionsDeleted_ = 0L;
				onChanged();
				return this;
			}

			// @@protoc_insertion_point(builder_scope:BulkDeleteResponse)
		}

		static {
			defaultInstance = new BulkDeleteResponse(
					true);
			defaultInstance.initFields();
		}

		// @@protoc_insertion_point(class_scope:BulkDeleteResponse)
	}

	/**
	 * Protobuf service {@code BulkDeleteService}
	 */
	public static abstract class BulkDeleteService implements
			org.apache.hadoop.hbase.shaded.com.google.protobuf.Service
	{
		protected BulkDeleteService() {}

		public interface Interface
		{
			/**
			 * <code>rpc delete(.BulkDeleteRequest) returns (.BulkDeleteResponse);</code>
			 */
			public abstract void delete(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcController controller,
					org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest request,
					org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcCallback<org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse> done );

		}

		public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Service newReflectiveService(
				final Interface impl ) {
			return new BulkDeleteService() {
				@java.lang.Override
				public void delete(
						org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcController controller,
						org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest request,
						org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcCallback<org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse> done ) {
					impl.delete(
							controller,
							request,
							done);
				}

			};
		}

		public static org.apache.hadoop.hbase.shaded.com.google.protobuf.BlockingService newReflectiveBlockingService(
				final BlockingInterface impl ) {
			return new org.apache.hadoop.hbase.shaded.com.google.protobuf.BlockingService() {
				public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.ServiceDescriptor getDescriptorForType() {
					return getDescriptor();
				}

				public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Message callBlockingMethod(
						org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.MethodDescriptor method,
						org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcController controller,
						org.apache.hadoop.hbase.shaded.com.google.protobuf.Message request )
						throws org.apache.hadoop.hbase.shaded.com.google.protobuf.ServiceException {
					if (method.getService() != getDescriptor()) {
						throw new java.lang.IllegalArgumentException(
								"Service.callBlockingMethod() given method descriptor for " + "wrong service type.");
					}
					switch (method.getIndex()) {
						case 0:
							return impl
									.delete(
											controller,
											(org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest) request);
						default:
							throw new java.lang.AssertionError(
									"Can't get here.");
					}
				}

				public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Message getRequestPrototype(
						org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.MethodDescriptor method ) {
					if (method.getService() != getDescriptor()) {
						throw new java.lang.IllegalArgumentException(
								"Service.getRequestPrototype() given method " + "descriptor for wrong service type.");
					}
					switch (method.getIndex()) {
						case 0:
							return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest
									.getDefaultInstance();
						default:
							throw new java.lang.AssertionError(
									"Can't get here.");
					}
				}

				public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Message getResponsePrototype(
						org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.MethodDescriptor method ) {
					if (method.getService() != getDescriptor()) {
						throw new java.lang.IllegalArgumentException(
								"Service.getResponsePrototype() given method " + "descriptor for wrong service type.");
					}
					switch (method.getIndex()) {
						case 0:
							return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse
									.getDefaultInstance();
						default:
							throw new java.lang.AssertionError(
									"Can't get here.");
					}
				}

			};
		}

		/**
		 * <code>rpc delete(.BulkDeleteRequest) returns (.BulkDeleteResponse);</code>
		 */
		public abstract void delete(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcController controller,
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest request,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcCallback<org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse> done );

		public static final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.ServiceDescriptor getDescriptor() {
			return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient
					.getDescriptor()
					.getServices()
					.get(
							0);
		}

		public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.ServiceDescriptor getDescriptorForType() {
			return getDescriptor();
		}

		public final void callMethod(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.MethodDescriptor method,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcController controller,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.Message request,
				org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.shaded.com.google.protobuf.Message> done ) {
			if (method.getService() != getDescriptor()) {
				throw new java.lang.IllegalArgumentException(
						"Service.callMethod() given method descriptor for wrong " + "service type.");
			}
			switch (method.getIndex()) {
				case 0:
					this
							.delete(
									controller,
									(org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest) request,
									org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcUtil
											.<org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse> specializeCallback(done));
					return;
				default:
					throw new java.lang.AssertionError(
							"Can't get here.");
			}
		}

		public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Message getRequestPrototype(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.MethodDescriptor method ) {
			if (method.getService() != getDescriptor()) {
				throw new java.lang.IllegalArgumentException(
						"Service.getRequestPrototype() given method " + "descriptor for wrong service type.");
			}
			switch (method.getIndex()) {
				case 0:
					return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest
							.getDefaultInstance();
				default:
					throw new java.lang.AssertionError(
							"Can't get here.");
			}
		}

		public final org.apache.hadoop.hbase.shaded.com.google.protobuf.Message getResponsePrototype(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.MethodDescriptor method ) {
			if (method.getService() != getDescriptor()) {
				throw new java.lang.IllegalArgumentException(
						"Service.getResponsePrototype() given method " + "descriptor for wrong service type.");
			}
			switch (method.getIndex()) {
				case 0:
					return org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse
							.getDefaultInstance();
				default:
					throw new java.lang.AssertionError(
							"Can't get here.");
			}
		}

		public static Stub newStub(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcChannel channel ) {
			return new Stub(
					channel);
		}

		public static final class Stub extends
				org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteService implements
				Interface
		{
			private Stub(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcChannel channel ) {
				this.channel = channel;
			}

			private final org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcChannel channel;

			public org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcChannel getChannel() {
				return channel;
			}

			public void delete(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcController controller,
					org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest request,
					org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcCallback<org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse> done ) {
				channel
						.callMethod(
								getDescriptor().getMethods().get(
										0),
								controller,
								request,
								org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse
										.getDefaultInstance(),
								org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcUtil
										.generalizeCallback(
												done,
												org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse.class,
												org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse
														.getDefaultInstance()));
			}
		}

		public static BlockingInterface newBlockingStub(
				org.apache.hadoop.hbase.shaded.com.google.protobuf.BlockingRpcChannel channel ) {
			return new BlockingStub(
					channel);
		}

		public interface BlockingInterface
		{
			public org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse delete(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcController controller,
					org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest request )
					throws org.apache.hadoop.hbase.shaded.com.google.protobuf.ServiceException;
		}

		private static final class BlockingStub implements
				BlockingInterface
		{
			private BlockingStub(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.BlockingRpcChannel channel ) {
				this.channel = channel;
			}

			private final org.apache.hadoop.hbase.shaded.com.google.protobuf.BlockingRpcChannel channel;

			public org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse delete(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.RpcController controller,
					org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteRequest request )
					throws org.apache.hadoop.hbase.shaded.com.google.protobuf.ServiceException {
				return (org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse) channel
						.callBlockingMethod(
								getDescriptor().getMethods().get(
										0),
								controller,
								request,
								org.locationtech.geowave.datastore.hbase.coprocessors.protobuf.HBaseBulkDeleteProtosClient.BulkDeleteResponse
										.getDefaultInstance());
			}

		}

		// @@protoc_insertion_point(class_scope:BulkDeleteService)
	}

	private static org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor internal_static_BulkDeleteRequest_descriptor;
	private static org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_BulkDeleteRequest_fieldAccessorTable;
	private static org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.Descriptor internal_static_BulkDeleteResponse_descriptor;
	private static org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_BulkDeleteResponse_fieldAccessorTable;

	public static org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor getDescriptor() {
		return descriptor;
	}

	private static org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor descriptor;
	static {
		java.lang.String[] descriptorData = {
			"\n\033HBaseBulkDeleteClient.proto\"\310\002\n\021BulkDe"
					+ "leteRequest\0225\n\ndeleteType\030\001 \002(\0162!.BulkDe"
					+ "leteRequest.BulkDeleteType\022\023\n\013rangeFilte"
					+ "r\030\002 \001(\014\022\016\n\006filter\030\003 \001(\014\022\r\n\005model\030\004 \001(\014\022\022"
					+ "\n\nadapterIds\030\005 \001(\014\022\"\n\032numericIndexStrate"
					+ "gyFilter\030\006 \001(\014\022\024\n\014blockCaching\030\007 \001(\010\022\021\n\t"
					+ "cacheSize\030\010 \001(\005\022\024\n\014rowBatchSize\030\t \002(\r\022\021\n"
					+ "\ttimestamp\030\n \001(\004\">\n\016BulkDeleteType\022\007\n\003RO"
					+ "W\020\000\022\n\n\006FAMILY\020\001\022\n\n\006COLUMN\020\002\022\013\n\007VERSION\020\003"
					+ "\"B\n\022BulkDeleteResponse\022\023\n\013rowsDeleted\030\001 ",
			"\002(\004\022\027\n\017versionsDeleted\030\002 \001(\0042F\n\021BulkDele"
					+ "teService\0221\n\006delete\022\022.BulkDeleteRequest\032"
					+ "\023.BulkDeleteResponseB^\n7org.locationtech" + ".geowave.datastore.hbase.query.protobufB"
					+ "\033HBaseBulkDeleteProtosClientH\001\210\001\001\240\001\001"
		};
		org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner = new org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
			public org.apache.hadoop.hbase.shaded.com.google.protobuf.ExtensionRegistry assignDescriptors(
					org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor root ) {
				descriptor = root;
				internal_static_BulkDeleteRequest_descriptor = getDescriptor().getMessageTypes().get(
						0);
				internal_static_BulkDeleteRequest_fieldAccessorTable = new org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_BulkDeleteRequest_descriptor,
						new java.lang.String[] {
							"DeleteType",
							"RangeFilter",
							"Filter",
							"Model",
							"AdapterIds",
							"NumericIndexStrategyFilter",
							"BlockCaching",
							"CacheSize",
							"RowBatchSize",
							"Timestamp",
						});
				internal_static_BulkDeleteResponse_descriptor = getDescriptor().getMessageTypes().get(
						1);
				internal_static_BulkDeleteResponse_fieldAccessorTable = new org.apache.hadoop.hbase.shaded.com.google.protobuf.GeneratedMessage.FieldAccessorTable(
						internal_static_BulkDeleteResponse_descriptor,
						new java.lang.String[] {
							"RowsDeleted",
							"VersionsDeleted",
						});
				return null;
			}
		};
		org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor.internalBuildGeneratedFileFrom(
				descriptorData,
				new org.apache.hadoop.hbase.shaded.com.google.protobuf.Descriptors.FileDescriptor[] {},
				assigner);
	}

	// @@protoc_insertion_point(outer_class_scope)
}
