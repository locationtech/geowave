{"paragraphs":[{"text":"%md\n## Welcome to the GeoWave GPX KMeans Example (EMR Version).\n##### This is a live note - you can run the code yourself.\n\n### Setup\n<p>\nThe only prerequisite to running this example is increasing your shell interpreter's timeout.<br>\nGo to the <b>Interpreter</b> page, and scroll down to the <b>'sh'</b> section. Click on the <b>'edit'</b> button.<br><br>\nSet the <b>'shell.command.timeout.millisecs'</b> entry to <b>600000</b> (10 minutes).\n</p>\n\n### Execution\n<p>\nThe list of paragraphs below needs to be run sequentially.<br>\nStart at the top, and click the <b>play</b> button in each paragraph, waiting for completion.<br>\nEach paragraph is labeled and commented so you can tell what's happening. A paragraph will be marked<br>\nwith a <b>FINISHED</b> indicator next to the play button when it has run without error.<br><br>\nEnjoy!\n</p>","dateUpdated":"2018-04-24T18:26:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Welcome to the GeoWave GPX KMeans Example (EMR Version).</h2>\n<h5>This is a live note - you can run the code yourself.</h5>\n<h3>Setup</h3>\n<p>\nThe only prerequisite to running this example is increasing your shell interpreter's timeout.<br>\nGo to the <b>Interpreter</b> page, and scroll down to the <b>'sh'</b> section. Click on the <b>'edit'</b> button.<br><br>\nSet the <b>'shell.command.timeout.millisecs'</b> entry to <b>600000</b> (10 minutes).\n</p>\n<h3>Execution</h3>\n<p>\nThe list of paragraphs below needs to be run sequentially.<br>\nStart at the top, and click the <b>play</b> button in each paragraph, waiting for completion.<br>\nEach paragraph is labeled and commented so you can tell what's happening. A paragraph will be marked<br>\nwith a <b>FINISHED</b> indicator next to the play button when it has run without error.<br><br>\nEnjoy!\n</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1524594363559_-596518550","id":"20170814-190601_1767735731","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3508"},{"title":"Import GPX Data","text":"%sh\ns3-dist-cp --src=s3://geowave-gpx-data/gpx --dest=hdfs://$HOSTNAME:8020/tmp/\n\n/opt/accumulo/bin/accumulo shell -u root -p secret -e \"importtable geowave.germany_gpx_SPATIAL_IDX /tmp/spatial\"\n/opt/accumulo/bin/accumulo shell -u root -p secret -e \"importtable geowave.germany_gpx_GEOWAVE_METADATA /tmp/metadata\"","dateUpdated":"2018-04-24T18:26:03+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{"SOUTH":"","EAST":"","NORTH":"","WEST":""},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"17/11/27 19:39:37 INFO s3distcp.S3DistCp: Running with args: -libjars /usr/share/aws/emr/s3-dist-cp/lib/guava-15.0.jar,/usr/share/aws/emr/s3-dist-cp/lib/s3-dist-cp-2.7.0.jar,/usr/share/aws/emr/s3-dist-cp/lib/s3-dist-cp.jar --src=s3://geowave-gpx-data/gpx --dest=hdfs://ip-10-0-0-36:8020/tmp/ \n17/11/27 19:39:37 INFO s3distcp.S3DistCp: S3DistCp args: --src=s3://geowave-gpx-data/gpx --dest=hdfs://ip-10-0-0-36:8020/tmp/ \n17/11/27 19:39:37 INFO s3distcp.S3DistCp: Using output path 'hdfs:/tmp/eb857b4f-b23c-4303-8ec4-13ad7f90b49c/output'\n17/11/27 19:39:37 INFO s3distcp.S3DistCp: GET http://169.254.169.254/latest/meta-data/placement/availability-zone result: us-east-1f\n17/11/27 19:39:40 INFO s3distcp.S3DistCp: DefaultAWSCredentialsProviderChain is used to create AmazonS3Client. KeyId: ASIAJA5NHL2X27HCG4FA\n17/11/27 19:39:41 INFO s3distcp.S3DistCp: Skipping key 'gpx/' because it ends with '/'\n17/11/27 19:39:41 INFO s3distcp.S3DistCp: Skipping key 'gpx/metadata/' because it ends with '/'\n17/11/27 19:39:41 INFO s3distcp.S3DistCp: Skipping key 'gpx/spatial/' because it ends with '/'\n17/11/27 19:39:41 INFO s3distcp.FileInfoListing: Opening new file: hdfs:/tmp/eb857b4f-b23c-4303-8ec4-13ad7f90b49c/files/1\n17/11/27 19:39:41 INFO s3distcp.S3DistCp: Created 1 files to copy 64 files \n17/11/27 19:39:41 INFO s3distcp.S3DistCp: Reducer number: 63\n17/11/27 19:39:41 INFO impl.TimelineClientImpl: Timeline service address: http://ip-10-0-0-36.ec2.internal:8188/ws/v1/timeline/\n17/11/27 19:39:41 INFO client.RMProxy: Connecting to ResourceManager at ip-10-0-0-36.ec2.internal/10.0.0.36:8032\n17/11/27 19:39:41 INFO input.FileInputFormat: Total input paths to process : 1\n17/11/27 19:39:41 INFO mapreduce.JobSubmitter: number of splits:1\n17/11/27 19:39:41 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1511810909522_0002\n17/11/27 19:39:42 INFO impl.YarnClientImpl: Submitted application application_1511810909522_0002\n17/11/27 19:39:42 INFO mapreduce.Job: The url to track the job: http://ip-10-0-0-36.ec2.internal:20888/proxy/application_1511810909522_0002/\n17/11/27 19:39:42 INFO mapreduce.Job: Running job: job_1511810909522_0002\n17/11/27 19:39:48 INFO mapreduce.Job: Job job_1511810909522_0002 running in uber mode : false\n17/11/27 19:39:48 INFO mapreduce.Job:  map 0% reduce 0%\n17/11/27 19:39:52 INFO mapreduce.Job:  map 100% reduce 0%\n17/11/27 19:39:57 INFO mapreduce.Job:  map 100% reduce 6%\n17/11/27 19:39:58 INFO mapreduce.Job:  map 100% reduce 10%\n17/11/27 19:39:59 INFO mapreduce.Job:  map 100% reduce 13%\n17/11/27 19:40:00 INFO mapreduce.Job:  map 100% reduce 16%\n17/11/27 19:40:01 INFO mapreduce.Job:  map 100% reduce 22%\n17/11/27 19:40:02 INFO mapreduce.Job:  map 100% reduce 25%\n17/11/27 19:40:03 INFO mapreduce.Job:  map 100% reduce 30%\n17/11/27 19:40:04 INFO mapreduce.Job:  map 100% reduce 37%\n17/11/27 19:40:05 INFO mapreduce.Job:  map 100% reduce 51%\n17/11/27 19:40:06 INFO mapreduce.Job:  map 100% reduce 57%\n17/11/27 19:40:08 INFO mapreduce.Job:  map 100% reduce 68%\n17/11/27 19:40:09 INFO mapreduce.Job:  map 100% reduce 71%\n17/11/27 19:40:10 INFO mapreduce.Job:  map 100% reduce 79%\n17/11/27 19:40:11 INFO mapreduce.Job:  map 100% reduce 81%\n17/11/27 19:40:12 INFO mapreduce.Job:  map 100% reduce 83%\n17/11/27 19:40:13 INFO mapreduce.Job:  map 100% reduce 86%\n17/11/27 19:40:14 INFO mapreduce.Job:  map 100% reduce 87%\n17/11/27 19:40:15 INFO mapreduce.Job:  map 100% reduce 95%\n17/11/27 19:40:16 INFO mapreduce.Job:  map 100% reduce 97%\n17/11/27 19:40:17 INFO mapreduce.Job:  map 100% reduce 98%\n17/11/27 19:40:18 INFO mapreduce.Job:  map 100% reduce 100%\n17/11/27 19:40:40 INFO mapreduce.Job: Job job_1511810909522_0002 completed successfully\n17/11/27 19:40:40 INFO mapreduce.Job: Counters: 54\n\tFile System Counters\n\t\tFILE: Number of bytes read=5864\n\t\tFILE: Number of bytes written=8397776\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=8501\n\t\tHDFS: Number of bytes written=11363269772\n\t\tHDFS: Number of read operations=321\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=190\n\t\tS3: Number of bytes read=11363269772\n\t\tS3: Number of bytes written=0\n\t\tS3: Number of read operations=0\n\t\tS3: Number of large read operations=0\n\t\tS3: Number of write operations=0\n\tJob Counters \n\t\tLaunched map tasks=1\n\t\tLaunched reduce tasks=63\n\t\tRack-local map tasks=1\n\t\tTotal time spent by all maps in occupied slots (ms)=107136\n\t\tTotal time spent by all reduces in occupied slots (ms)=66421344\n\t\tTotal time spent by all map tasks (ms)=2232\n\t\tTotal time spent by all reduce tasks (ms)=691889\n\t\tTotal vcore-milliseconds taken by all map tasks=2232\n\t\tTotal vcore-milliseconds taken by all reduce tasks=691889\n\t\tTotal megabyte-milliseconds taken by all map tasks=3428352\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=2125483008\n\tMap-Reduce Framework\n\t\tMap input records=64\n\t\tMap output records=64\n\t\tMap output bytes=8758\n\t\tMap output materialized bytes=5612\n\t\tInput split bytes=151\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=64\n\t\tReduce shuffle bytes=5612\n\t\tReduce input records=64\n\t\tReduce output records=0\n\t\tSpilled Records=128\n\t\tShuffled Maps =63\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=63\n\t\tGC time elapsed (ms)=14524\n\t\tCPU time spent (ms)=630930\n\t\tPhysical memory (bytes) snapshot=30090629120\n\t\tVirtual memory (bytes) snapshot=297350909952\n\t\tTotal committed heap usage (bytes)=40637038592\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=8350\n\tFile Output Format Counters \n\t\tBytes Written=0\n17/11/27 19:40:40 INFO s3distcp.S3DistCp: Try to recursively delete hdfs:/tmp/eb857b4f-b23c-4303-8ec4-13ad7f90b49c/tempspace\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/opt/accumulo-1.8.1/lib/slf4j-log4j12.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n2017-11-27 19:40:41,726 [conf.ConfigSanityCheck] WARN : Use of instance.dfs.uri and instance.dfs.dir are deprecated. Consider using instance.volumes instead.\n2017-11-27 19:40:42,468 [htrace.SpanReceiverBuilder] ERROR: SpanReceiverBuilder cannot find SpanReceiver class org.apache.accumulo.tracer.ZooTraceClient: disabling span receiver.\n2017-11-27 19:40:42,468 [trace.DistributedTrace] WARN : Failed to load SpanReceiver org.apache.accumulo.tracer.ZooTraceClient\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/opt/accumulo-1.8.1/lib/slf4j-log4j12.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n2017-11-27 19:40:46,302 [conf.ConfigSanityCheck] WARN : Use of instance.dfs.uri and instance.dfs.dir are deprecated. Consider using instance.volumes instead.\n2017-11-27 19:40:47,035 [htrace.SpanReceiverBuilder] ERROR: SpanReceiverBuilder cannot find SpanReceiver class org.apache.accumulo.tracer.ZooTraceClient: disabling span receiver.\n2017-11-27 19:40:47,036 [trace.DistributedTrace] WARN : Failed to load SpanReceiver org.apache.accumulo.tracer.ZooTraceClient\n2017-11-27 19:40:47,467 [impl.TableOperationsImpl] INFO : Imported table sets 'table.iterator.minc.STATS_COMBINER' to '10,mil.nga.giat.geowave.datastore.accumulo.MergingCombiner'.  Ensure this class is on Accumulo classpath.\n2017-11-27 19:40:47,467 [impl.TableOperationsImpl] INFO : Imported table sets 'table.iterator.majc.STATS_COMBINER' to '10,mil.nga.giat.geowave.datastore.accumulo.MergingCombiner'.  Ensure this class is on Accumulo classpath.\n2017-11-27 19:40:47,467 [impl.TableOperationsImpl] INFO : Imported table sets 'table.iterator.scan.STATS_COMBINER' to '10,mil.nga.giat.geowave.datastore.accumulo.MergingCombiner'.  Ensure this class is on Accumulo classpath.\n"}]},"apps":[],"jobName":"paragraph_1524594363559_-596518550","id":"20170815-204020_1185378225","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3509"},{"text":"%spark\n\n//Load Java environment vars, and convert to Scala map\nimport scala.collection.JavaConversions._\nval jenvironmentVars = System.getenv()\n//Use environmentVars map to pull environment vars for use in spark\nval environmentVars = mapAsScalaMap(jenvironmentVars)\nfor ((k,v) <- environmentVars) println(s\"key: $k, value: $v\")\n\n//Bind the hostname to the angular frontend to be used in map creation script\nz.angularBind(\"hostname\", environmentVars.getOrElse(\"HOSTNAME\", \"localhost\"))\n","dateUpdated":"2018-04-24T18:26:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import scala.collection.JavaConversions._\njenvironmentVars: java.util.Map[String,String] =\n{PATH=/usr/local/sbin:/usr/local/bin:/usr/bin:/usr/sbin:/sbin:/bin, ZEPPELIN_PORT=8890, BASH_FUNC_run_prestart()=() {  su -s /bin/bash $SVC_USER -c \"cd $WORKING_DIR && $EXEC_PATH --config '$CONF_DIR' start > /dev/null 2>&1\"\n}, ZEPPELIN_LOG_DIR=/var/log/zeppelin, HADOOP_CONF_DIR=/etc/hadoop/conf, SPARK_MASTER_WEBUI_PORT=8080, ZEPPELIN_WAR=/usr/lib/zeppelin/zeppelin-web-0.7.3.war, ZEPPELIN_ENCODING=UTF-8, SPARK_SUBMIT_OPTIONS=--driver-memory 11059M --executor-memory 9830M --jars /usr/local/geowave/tools/geowave-tools-0.9.6-apache.jar --conf 'spark.executorEnv.PYTHONPATH=/usr/lib/spark/python/lib/py4j-src.zip:/usr/lib/spark/python/:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-src.zip' --conf spark.yarn.isPython=true, PIDFILE=/var/run/zeppelin/z...environmentVars: scala.collection.mutable.Map[String,String] =\nMap(PATH -> /usr/local/sbin:/usr/local/bin:/usr/bin:/usr/sbin:/sbin:/bin, ZEPPELIN_PORT -> 8890, BASH_FUNC_run_prestart() -> () {  su -s /bin/bash $SVC_USER -c \"cd $WORKING_DIR && $EXEC_PATH --config '$CONF_DIR' start > /dev/null 2>&1\"\n}, ZEPPELIN_LOG_DIR -> /var/log/zeppelin, HADOOP_CONF_DIR -> /etc/hadoop/conf, SPARK_MASTER_WEBUI_PORT -> 8080, ZEPPELIN_WAR -> /usr/lib/zeppelin/zeppelin-web-0.7.3.war, ZEPPELIN_ENCODING -> UTF-8, SPARK_SUBMIT_OPTIONS -> --driver-memory 11059M --executor-memory 9830M --jars /usr/local/geowave/tools/geowave-tools-0.9.6-apache.jar --conf 'spark.executorEnv.PYTHONPATH=/usr/lib/spark/python/lib/py4j-src.zip:/usr/lib/spark/python/:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-src.zip' --conf spark.yar...key: PATH, value: /usr/local/sbin:/usr/local/bin:/usr/bin:/usr/sbin:/sbin:/bin\nkey: ZEPPELIN_PORT, value: 8890\nkey: BASH_FUNC_run_prestart(), value: () {  su -s /bin/bash $SVC_USER -c \"cd $WORKING_DIR && $EXEC_PATH --config '$CONF_DIR' start > /dev/null 2>&1\"\n}\nkey: ZEPPELIN_LOG_DIR, value: /var/log/zeppelin\nkey: HADOOP_CONF_DIR, value: /etc/hadoop/conf\nkey: SPARK_MASTER_WEBUI_PORT, value: 8080\nkey: ZEPPELIN_WAR, value: /usr/lib/zeppelin/zeppelin-web-0.7.3.war\nkey: ZEPPELIN_ENCODING, value: UTF-8\nkey: SPARK_SUBMIT_OPTIONS, value: --driver-memory 11059M --executor-memory 9830M --jars /usr/local/geowave/tools/geowave-tools-0.9.6-apache.jar --conf 'spark.executorEnv.PYTHONPATH=/usr/lib/spark/python/lib/py4j-src.zip:/usr/lib/spark/python/:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-src.zip' --conf spark.yarn.isPython=true\nkey: PIDFILE, value: /var/run/zeppelin/zeppelin.pid\nkey: ZEPPELIN_NICENESS, value: 0\nkey: SPARK_ENV_LOADED, value: 1\nkey: JAVA_OPTS, value:   -Dfile.encoding=UTF-8 -Xms1024m -Xmx1024m -XX:MaxPermSize=512m -Dlog4j.configuration=file:///etc/zeppelin/conf/log4j.properties -Dzeppelin.log.file=/var/log/zeppelin/zeppelin-zeppelin-ip-10-0-0-36.log  -Dfile.encoding=UTF-8 -Xms1024m -Xmx1024m -XX:MaxPermSize=512m -Dlog4j.configuration=file:///etc/zeppelin/conf/log4j.properties\nkey: DESC, value: Zeppelin\nkey: JAVA_INTP_OPTS, value:  -Dfile.encoding=UTF-8 -Dlog4j.configuration=file:///etc/zeppelin/conf/log4j.properties -Dzeppelin.log.file=/var/log/zeppelin/zeppelin-interpreter-spark-zeppelin-ip-10-0-0-36.log\nkey: EXEC_PATH, value: /usr/lib/zeppelin/bin/zeppelin-daemon.sh\nkey: SLEEP_TIME, value: 10\nkey: ZEPPELIN_CONF_DIR, value: /etc/zeppelin/conf\nkey: LD_LIBRARY_PATH, value: /usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native\nkey: HADOOP_HOME_WARN_SUPPRESS, value: true\nkey: LOGNAME, value: zeppelin\nkey: JSVC_HOME, value: /usr/lib/bigtop-utils\nkey: PWD, value: /var/lib/zeppelin\nkey: HADOOP_PREFIX, value: /usr/lib/hadoop\nkey: ZEPPELIN_PID, value: /var/run/zeppelin/zeppelin-interpreter-spark-zeppelin-ip-10-0-0-36.pid\nkey: PYTHONPATH, value: /usr/lib/spark/python/lib/py4j-0.10.4-src.zip:/usr/lib/spark/python/:\nkey: HIVE_SERVER2_THRIFT_BIND_HOST, value: 0.0.0.0\nkey: SPARK_SUBMIT, value: /usr/lib/spark/bin/spark-submit\nkey: SHELL, value: /bin/bash\nkey: WORKING_DIR, value: /var/lib/zeppelin\nkey: ZEPPELIN_INTP_MEM, value: -Xms1024m -Xmx1024m -XX:MaxPermSize=512m\nkey: SPARK_MASTER_PORT, value: 7077\nkey: HADOOP_YARN_HOME, value: /usr/lib/hadoop-yarn\nkey: UPSTART_INSTANCE, value: \nkey: SPARK_MASTER_IP, value: ip-10-0-0-36.ec2.internal\nkey: DAEMON_FLAGS, value: \nkey: HADOOP_HOME, value: /usr/lib/hadoop\nkey: DAEMON, value: zeppelin\nkey: SHLVL, value: 4\nkey: SPARK_LOG_DIR, value: /var/log/spark\nkey: MASTER, value: yarn-client\nkey: UPSTART_JOB, value: zeppelin\nkey: JAVA_HOME, value: /usr/lib/jvm/java-openjdk\nkey: CONF_DIR, value: /etc/zeppelin/conf\nkey: TERM, value: linux\nkey: XFILESEARCHPATH, value: /usr/dt/app-defaults/%L/Dt\nkey: SPARK_WORKER_DIR, value: /var/run/spark/work\nkey: LANG, value: en_US.UTF-8\nkey: SPARK_SCALA_VERSION, value: 2.10\nkey: HADOOP_LIBEXEC_DIR, value: /usr/lib/hadoop/libexec\nkey: ZEPPELIN_WAR_TEMPDIR, value: /var/run/zeppelin/webapps\nkey: SPARK_HOME, value: /usr/lib/spark\nkey: ZEPPELIN_NOTEBOOK_DIR, value: /var/lib/zeppelin/notebook\nkey: HADOOP_HDFS_HOME, value: /usr/lib/hadoop-hdfs\nkey: ZEPPELIN_RUNNER, value: /usr/lib/jvm/java-openjdk/bin/java\nkey: HADOOP_MAPRED_HOME, value: /usr/lib/hadoop-mapreduce\nkey: HADOOP_COMMON_HOME, value: /usr/lib/hadoop\nkey: PYTHONHASHSEED, value: 0\nkey: ZEPPELIN_HOME, value: /usr/lib/zeppelin\nkey: HIVE_CONF_DIR, value: /etc/hive/conf\nkey: USER, value: zeppelin\nkey: CLASSPATH, value: :/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar\nkey: ZEPPELIN_PID_DIR, value: /var/run/zeppelin\nkey: ZEPPELIN_MEM, value: -Xms1024m -Xmx1024m -XX:MaxPermSize=512m\nkey: SPARK_DAEMON_JAVA_OPTS, value:  -XX:OnOutOfMemoryError='kill -9 %p'\nkey: HOSTNAME, value: ip-10-0-0-36\nkey: ZEPPELIN_IDENT_STRING, value: zeppelin\nkey: NLSPATH, value: /usr/dt/lib/nls/msg/%L/%N.cat\nkey: STANDALONE_SPARK_MASTER_HOST, value: ip-10-0-0-36.ec2.internal\nkey: SPARK_PUBLIC_DNS, value: ip-10-0-0-36.ec2.internal\nkey: SVC_USER, value: zeppelin\nkey: SPARK_WORKER_PORT, value: 7078\nkey: ZEPPELIN_INTERPRETER_REMOTE_RUNNER, value: bin/interpreter.sh\nkey: HIVE_SERVER2_THRIFT_PORT, value: 10001\nkey: HOME, value: /var/lib/zeppelin\nkey: SPARK_WORKER_WEBUI_PORT, value: 8081\n"}]},"apps":[],"jobName":"paragraph_1524594363559_-596518550","id":"20171117-145757_486146312","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3510"},{"title":"Configure GeoWave","text":"%sh\n# clear out potential old runs\ngeowave config rmstore kmeans_hbase\ngeowave config rmstore germany_gpx_accumulo\n\n# configure geowave connection params for name stores \"germany_gpx_accumulo\" and \"kmeans_hbase\"\ngeowave config addstore germany_gpx_accumulo --gwNamespace geowave.germany_gpx -t accumulo --zookeeper $HOSTNAME:2181 --instance accumulo --user root --password secret\ngeowave config addstore kmeans_hbase --gwNamespace geowave.kmeans -t hbase --zookeeper $HOSTNAME:2181\n\n# set up geoserver\ngeowave config geoserver \"$HOSTNAME:8000\"\n\n# add gpx layer\ngeowave gs addlayer germany_gpx_accumulo -id gpxpoint\nwget s3.amazonaws.com/geowave/latest/scripts/emr/quickstart/SubsamplePoints.sld\ngeowave gs addstyle SubsamplePoints -sld SubsamplePoints.sld\ngeowave gs setls gpxpoint --styleName SubsamplePoints\n","dateUpdated":"2018-04-24T18:26:03+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"geoserver.url=ip-10-0-0-36:8000\n\n27 Nov 19:41:55 WARN [client.ClientConfiguration] - Found no client.conf in default paths. Using default client configuration values.\nNov 27, 2017 7:41:56 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 27, 2017 7:41:56 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 27, 2017 7:41:56 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nNov 27, 2017 7:41:56 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionProvider', but ApplicationContext is unset.\nNov 27, 2017 7:41:56 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nNov 27, 2017 7:41:56 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 27, 2017 7:41:56 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 27, 2017 7:41:56 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nNov 27, 2017 7:41:56 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionProvider', but ApplicationContext is unset.\nNov 27, 2017 7:41:56 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nAdd GeoServer layer for 'germany_gpx_accumulo: OK : {\n  \"description\": \"Successfully added:\",\n  \"layers\": [  {\n    \"id\": \"gpxpoint\",\n    \"type\": \"vector\"\n  }]\n}\n--2017-11-27 19:42:01--  http://s3.amazonaws.com/geowave/latest/scripts/emr/quickstart/SubsamplePoints.sld\nResolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.115.50\nConnecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.115.50|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2237 (2.2K) [binary/octet-stream]\nSaving to: ‘SubsamplePoints.sld’\n\n     0K ..                                                    100%  546M=0s\n\n2017-11-27 19:42:01 (546 MB/s) - ‘SubsamplePoints.sld’ saved [2237/2237]\n\nAdd style for 'SubsamplePoints' on GeoServer: OK\nSet style for GeoServer layer 'gpxpoint: OK\n"}]},"apps":[],"jobName":"paragraph_1524594363560_-598442294","id":"20170809-181755_1512238840","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3511"},{"text":"%spark\n//Import classes from spark\nimport org.apache.spark.api.java.JavaSparkContext\n//DataFrame = type alias Dataset<Row>\nimport org.apache.spark.sql.DataFrame\nimport spark.implicits._\n\n//Import classes from geowave\nimport mil.nga.giat.geowave.datastore.hbase.cli.config.HBaseRequiredOptions\nimport mil.nga.giat.geowave.datastore.accumulo.cli.config.AccumuloRequiredOptions\nimport mil.nga.giat.geowave.analytic.spark.RDDOptions\nimport mil.nga.giat.geowave.analytic.spark.GeoWaveRDDLoader\nimport mil.nga.giat.geowave.analytic.spark.kmeans.KMeansRunner\nimport mil.nga.giat.geowave.core.store.query.QueryOptions\nimport mil.nga.giat.geowave.analytic.spark.GeoWaveRDD\nimport mil.nga.giat.geowave.analytic.spark.sparksql.SimpleFeatureDataFrame\nimport mil.nga.giat.geowave.core.index.ByteArrayId","dateUpdated":"2018-04-24T18:26:46+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.api.java.JavaSparkContext\nimport org.apache.spark.sql.DataFrame\nimport spark.implicits._\nimport mil.nga.giat.geowave.datastore.hbase.operations.config.HBaseRequiredOptions\nimport mil.nga.giat.geowave.datastore.accumulo.operations.config.AccumuloRequiredOptions\nimport mil.nga.giat.geowave.analytic.spark.kmeans.KMeansRunner\nimport mil.nga.giat.geowave.core.store.query.QueryOptions\nimport mil.nga.giat.geowave.analytic.spark.GeoWaveRDD\nimport mil.nga.giat.geowave.analytic.spark.sparksql.SimpleFeatureDataFrame\nimport mil.nga.giat.geowave.core.index.ByteArrayId\n"}]},"apps":[],"jobName":"paragraph_1524594363560_-598442294","id":"20171117-143415_1121588696","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3512"},{"text":"%spark\n\n//Grab hostname from environment vars\nval hostname = environmentVars.getOrElse(\"HOSTNAME\", \"invalid-host\")\nprintln(s\"hostname= $hostname\")\n\n//Setup datastores\nval input_store = new AccumuloRequiredOptions()\ninput_store.setInstance(\"accumulo\")\ninput_store.setUser(\"root\")\ninput_store.setPassword(\"secret\")\ninput_store.setZookeeper(hostname + \":2181\")\ninput_store.setGeowaveNamespace(\"geowave.germany_gpx\")\n\nval output_store = new HBaseRequiredOptions()\noutput_store.setZookeeper(hostname + \":2181\")\noutput_store.setGeowaveNamespace(\"geowave.kmeans\")\n\n//Create instances of store plugin options, and KMeansRunner\nval input_store_plugin = input_store.createPluginOptions()\nval output_store_plugin = output_store.createPluginOptions()\nval jsc = JavaSparkContext.fromSparkContext(sc)\nval kmeans_runner = new KMeansRunner()","dateUpdated":"2018-04-24T18:26:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"hostname: String = ip-10-0-0-36\nhostname= ip-10-0-0-36\ninput_store: mil.nga.giat.geowave.datastore.accumulo.operations.config.AccumuloRequiredOptions = mil.nga.giat.geowave.datastore.accumulo.operations.config.AccumuloRequiredOptions@bc516ff\noutput_store: mil.nga.giat.geowave.datastore.hbase.operations.config.HBaseRequiredOptions = mil.nga.giat.geowave.datastore.hbase.operations.config.HBaseRequiredOptions@32b51512\ninput_store_plugin: mil.nga.giat.geowave.core.store.operations.remote.options.DataStorePluginOptions = mil.nga.giat.geowave.core.store.operations.remote.options.DataStorePluginOptions@75169b65\noutput_store_plugin: mil.nga.giat.geowave.core.store.operations.remote.options.DataStorePluginOptions = mil.nga.giat.geowave.core.store.operations.remote.options.DataStorePluginOptions@20c7db21\njsc: org.apache.spark.api.java.JavaSparkContext = org.apache.spark.api.java.JavaSparkContext@3bf8841e\nkmeans_runner: mil.nga.giat.geowave.analytic.spark.kmeans.KMeansRunner = mil.nga.giat.geowave.analytic.spark.kmeans.KMeansRunner@41475ce7\n"}]},"apps":[],"jobName":"paragraph_1524594363560_-598442294","id":"20171117-144307_1205081062","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3513"},{"text":"%sh\n#clear old potential runs\ngeowave remote clear kmeans_hbase","dateUpdated":"2018-04-24T18:26:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/sh","results":{},"enabled":true,"editorSetting":{"language":"sh","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"27 Nov 14:56:59 INFO [zookeeper.RecoverableZooKeeper] - Process identifier=hconnection-0x7d94beb9 connecting to ZooKeeper ensemble=ip-10-0-0-14:2181\n27 Nov 14:57:00 INFO [client.HBaseAdmin] - Started disable of geowave.kmeans_GEOWAVE_METADATA\n27 Nov 14:57:08 INFO [client.HBaseAdmin] - Disabled geowave.kmeans_GEOWAVE_METADATA\n27 Nov 14:57:17 INFO [client.HBaseAdmin] - Deleted geowave.kmeans_GEOWAVE_METADATA\n27 Nov 14:57:17 INFO [client.HBaseAdmin] - Started disable of geowave.kmeans_SPATIAL_IDX\n27 Nov 14:57:21 INFO [client.HBaseAdmin] - Disabled geowave.kmeans_SPATIAL_IDX\n27 Nov 14:58:29 INFO [client.HBaseAdmin] - Deleted geowave.kmeans_SPATIAL_IDX\n"}]},"apps":[],"jobName":"paragraph_1524594363560_-598442294","id":"20171122-192044_1893177986","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3514"},{"text":"%spark\n//set the appropriate properties of the runner\nkmeans_runner.setJavaSparkContext(JavaSparkContext.fromSparkContext(sc))\nkmeans_runner.setAdapterId(\"gpxpoint\")\nkmeans_runner.setNumClusters(8)\nkmeans_runner.setInputDataStore(input_store_plugin)\nkmeans_runner.setOutputDataStore(output_store_plugin)\nkmeans_runner.setCqlFilter(\"BBOX(geometry,  13.3, 52.45, 13.5, 52.5)\")\nkmeans_runner.setCentroidTypeName(\"mycentroids\")\nkmeans_runner.setHullTypeName(\"myhulls\")\nkmeans_runner.setGenerateHulls(true)\nkmeans_runner.setComputeHullData(true)\n\n//execute the kmeans runner\nkmeans_runner.run()","dateUpdated":"2018-04-24T18:26:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1524594363560_-598442294","id":"20171117-150524_1487053014","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3515"},{"title":"Add KMeans Results to GeoServer","text":"%sh\n\n# add the centroids layer\ngeowave gs addlayer kmeans_hbase -id mycentroids\ngeowave gs setls mycentroids --styleName point\n\n# add the hulls layer\ngeowave gs addlayer kmeans_hbase -id myhulls\ngeowave gs setls myhulls --styleName line","dateUpdated":"2018-04-24T18:26:03+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sh","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"26 Nov 20:35:31 INFO [zookeeper.RecoverableZooKeeper] - Process identifier=hconnection-0x4e928fbf connecting to ZooKeeper ensemble=ip-10-0-0-106:2181\nNov 26, 2017 8:35:33 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 26, 2017 8:35:33 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 26, 2017 8:35:33 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nNov 26, 2017 8:35:33 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionProvider', but ApplicationContext is unset.\nNov 26, 2017 8:35:33 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nNov 26, 2017 8:35:33 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 26, 2017 8:35:33 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 26, 2017 8:35:33 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nNov 26, 2017 8:35:33 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionProvider', but ApplicationContext is unset.\nNov 26, 2017 8:35:33 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nAdd GeoServer layer for 'kmeans_hbase: OK : {\n  \"description\": \"Successfully added:\",\n  \"layers\": [  {\n    \"id\": \"mycentroids\",\n    \"type\": \"vector\"\n  }]\n}\nSet style for GeoServer layer 'mycentroids: OK\n26 Nov 20:35:38 INFO [zookeeper.RecoverableZooKeeper] - Process identifier=hconnection-0x4e928fbf connecting to ZooKeeper ensemble=ip-10-0-0-106:2181\nNov 26, 2017 8:35:39 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 26, 2017 8:35:39 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 26, 2017 8:35:39 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nNov 26, 2017 8:35:39 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionProvider', but ApplicationContext is unset.\nNov 26, 2017 8:35:39 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nNov 26, 2017 8:35:39 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 26, 2017 8:35:39 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'GeoServerResourceLoader', but ApplicationContext is unset.\nNov 26, 2017 8:35:39 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nNov 26, 2017 8:35:39 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionProvider', but ApplicationContext is unset.\nNov 26, 2017 8:35:39 PM org.geoserver.platform.GeoServerExtensions checkContext\nWARNING: Extension lookup 'ExtensionFilter', but ApplicationContext is unset.\nAdd GeoServer layer for 'kmeans_hbase: OK : {\n  \"description\": \"Successfully added:\",\n  \"layers\": [  {\n    \"id\": \"myhulls\",\n    \"type\": \"vector\"\n  }]\n}\nSet style for GeoServer layer 'myhulls: OK\n"}]},"apps":[],"jobName":"paragraph_1524594363561_-598827043","id":"20170817-030121_1271873891","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3516"},{"text":"%angular\n<link rel=\"stylesheet\" href=\"https://unpkg.com/leaflet@1.2.0/dist/leaflet.css\" />\n<h3>GeoWave Leaflet Map</h3>\n<div type=\"hidden\" id=\"leaflet-input\" host={{hostname}} />\n<div id=\"map\" style=\"height: 600px; width: 100%\"></div>\n<script type=\"text/javascript\" id=\"leaflet-script\">\nfunction getHostname() {\n    var element = document.getElementById('leaflet-input');\n    return element.getAttribute('host');\n}\n\nfunction initMap() {\n    var map = L.map('map').setView([50.00, 10.00], 5);\n    \n    var host = getHostname();\n    mapLink = '<a href=\"http://www.esri.com/\">Esri</a>';\n    wholink = 'i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community';\n\n    var basemaps = {\n        OSM: L.tileLayer('http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {\n            attribution: 'Map data &copy; <a href=\"http://openstreetmap.org\">OpenStreetMap</a> contributors',\n            maxZoom: 15,\n            minZoom: 2\n        }),\n        Satellite:L.tileLayer(\n            'http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}', {\n            attribution: '&copy; '+mapLink+', '+wholink,\n            maxZoom: 18,\n        })\n    };\n    \n    var overlays = {\n        GPX:L.tileLayer.wms('http://'+host+':8000/geoserver/geowave/wms?', {\n            layers: 'geowave:gpxpoint',\n            format: 'image/png',\n            transparent: true\n        }),\n        \n        KMeansCentroids:L.tileLayer.wms('http://'+host+':8000/geoserver/geowave/wms?', {\n            layers: 'geowave:mycentroids',\n            format: 'image/png',\n            transparent: true\n        }),\n        \n        KMeansHulls:L.tileLayer.wms('http://'+host+':8000/geoserver/geowave/wms?', {\n            layers: 'geowave:myhulls',\n            format: 'image/png',\n            transparent: true\n        })\n    };\n\n    L.control.layers(basemaps, overlays).addTo(map);\n    \n    basemaps.OSM.addTo(map);\n}\n\nangular.element(document).ready(function () {\nif (window.L) {\n    initMap();\n} else {\n    console.log('Loading Leaflet library');\n    var sc = document.createElement('script');\n    sc.type = 'text/javascript';\n    sc.src = 'https://unpkg.com/leaflet@1.2.0/dist/leaflet.js';\n    sc.onload = initMap;\n    sc.onerror = function(err) { alert(err); }\n    document.getElementsByTagName('head')[0].appendChild(sc);\n}\n});\n</script>\n","dateUpdated":"2018-04-24T18:26:03+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/undefined","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"ANGULAR","data":"<link rel=\"stylesheet\" href=\"https://unpkg.com/leaflet@1.2.0/dist/leaflet.css\" />\n<h3>GeoWave Leaflet Map</h3>\n<div type=\"hidden\" id=\"leaflet-input\" ng-value=z.get('hostname') host={{hostname}} />\n<div id=\"map\" style=\"height: 600px; width: 100%\"></div>\n<script type=\"text/javascript\" id=\"leaflet-script\">\nfunction getHostname() {\n    var element = document.getElementById('leaflet-input');\n    return element.getAttribute('host');\n}\n\nfunction initMap() {\n    var map = L.map('map').setView([50.00, 10.00], 5);\n    \n    var host = getHostname();\n    mapLink = '<a href=\"http://www.esri.com/\">Esri</a>';\n    wholink = 'i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community';\n\n    var basemaps = {\n        OSM: L.tileLayer('http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {\n            attribution: 'Map data &copy; <a href=\"http://openstreetmap.org\">OpenStreetMap</a> contributors',\n            maxZoom: 15,\n            minZoom: 2\n        }),\n        Satellite:L.tileLayer(\n            'http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}', {\n            attribution: '&copy; '+mapLink+', '+wholink,\n            maxZoom: 18,\n        })\n    };\n    \n    var overlays = {\n        GPX:L.tileLayer.wms('http://'+host+':8000/geoserver/geowave/wms?', {\n            layers: 'geowave:gpxpoint',\n            format: 'image/png',\n            transparent: true\n        }),\n        \n        KMeansCentroids:L.tileLayer.wms('http://'+host+':8000/geoserver/geowave/wms?', {\n            layers: 'geowave:mycentroids',\n            format: 'image/png',\n            transparent: true\n        }),\n        \n        KMeansHulls:L.tileLayer.wms('http://'+host+':8000/geoserver/geowave/wms?', {\n            layers: 'geowave:myhulls',\n            format: 'image/png',\n            transparent: true\n        })\n    };\n\n    L.control.layers(basemaps, overlays).addTo(map);\n    \n    basemaps.OSM.addTo(map);\n}\n\nangular.element(document).ready(function () {\nif (window.L) {\n    initMap();\n} else {\n    console.log('Loading Leaflet library');\n    var sc = document.createElement('script');\n    sc.type = 'text/javascript';\n    sc.src = 'https://unpkg.com/leaflet@1.2.0/dist/leaflet.js';\n    sc.onload = initMap;\n    sc.onerror = function(err) { alert(err); }\n    document.getElementsByTagName('head')[0].appendChild(sc);\n}\n});\n</script>"}]},"apps":[],"jobName":"paragraph_1524594363561_-598827043","id":"20170817-030613_874309201","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3517"},{"title":"Load KMeans Centroid CSV into DataFrame","text":"%spark\n\ndef create_dataframe(adapter_name : String) : DataFrame = {\n    //Create the dataframe and get a rdd for the output of kmeans\n    var sf_df = new SimpleFeatureDataFrame(spark)\n    val adapter_id = new ByteArrayId(adapter_name)\n    \n    var queryOptions = null : Option[QueryOptions]\n    val adapterIt = output_store_plugin.createAdapterStore().getAdapters()\n    while (adapterIt.hasNext()) {\n        val adapter = adapterIt.next()\n        if (adapter.getAdapterId().equals(adapter_id)) {\n            val adapterForQuery = adapter\n            queryOptions = Some(new QueryOptions(adapterForQuery))\n        }\n    }\n    val loadOpts = new RDDOptions()\n    loadOpts.setQueryOptions(queryOptions.getOrElse(null))\n    val output_rdd = GeoWaveRDDLoader.loadRDD(sc, output_store_plugin, loadOpts))\n    sf_df.init(output_store_plugin, adapter_id)\n    \n    return sf_df.getDataFrame(output_rdd)\n}\n\nvar df = create_dataframe(\"mycentroids\")\ndf.show()\n\n// Convert geom string to lat/long\ncase class KMeansRow(lat: Double, lon: Double, ClusterIndex : Int)\nval kmeansData = df.map(row => {\n    val geom_index = row.fieldIndex(\"geom\")\n    val geom = row.getString(geom_index)\n    val cluster_index = row.getInt(row.fieldIndex(\"ClusterIndex\"))\n    val lat_start = geom.lastIndexOf(\" \") + 1\n    val lat_end = geom.lastIndexOf(\")\")\n    val lat = geom.substring(lat_start, lat_end)\n    val lonStart = geom.indexOf(\"(\") + 1\n    val lonStop = geom.indexOf(\" \", lonStart)\n    val lon = geom.substring(lonStart, lonStop)\n    KMeansRow(lat=lat.toDouble, lon=lon.toDouble, ClusterIndex=cluster_index)\n    })\n// send the results to the front end (Leaflet map)\nz.angularBind(\"pins\", kmeansData.collect())\n// register a view for SQL queries\nkmeansData.createOrReplaceTempView(\"kmeans\")\n","dateUpdated":"2018-04-24T18:27:15+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"create_dataframe: (adapter_name: String)org.apache.spark.sql.DataFrame\ndf: org.apache.spark.sql.DataFrame = [geom: string, ClusterIndex: int]\n+--------------------+------------+\n|                geom|ClusterIndex|\n+--------------------+------------+\n|POINT (13.3195852...|           0|\n|POINT (13.3139355...|           5|\n|POINT (13.3392341...|           6|\n|POINT (13.4709106...|           3|\n|POINT (13.3619528...|           4|\n|POINT (13.3888137...|           1|\n|POINT (13.4312593...|           2|\n|POINT (13.4756306...|           7|\n+--------------------+------------+\n\ndefined class KMeansRow\nkmeansData: org.apache.spark.sql.Dataset[KMeansRow] = [lat: double, lon: double ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1524594363561_-598827043","id":"20170814-174640_830156690","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3518"},{"title":"Display the KMeans Centroids Table","text":"%sql\nselect lat as Latitude, lon as Longitude from kmeans","dateUpdated":"2018-04-24T18:26:03+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":8,"editorMode":"ace/mode/sql","editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"Latitude\tLongitude\n52.46351825250708\t13.319585220066669\n52.48782846644896\t13.313935518966645\n52.48274354548128\t13.339234131447801\n52.491618128998084\t13.470910672079846\n52.479834322332394\t13.361952882747175\n52.48307815695488\t13.388813779887156\n52.48417492312525\t13.43125930391005\n52.46475242616019\t13.475630651565233\n"}]},"apps":[],"jobName":"paragraph_1524594363561_-598827043","id":"20170809-203309_1972137502","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3519"},{"text":"%angular\r\n\r\n<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/leaflet/0.7.5/leaflet.css\" />\r\n<h3>Client-side Integration</h3>\r\n<div id=\"map2\" style=\"height: 600px; width: 100%\"></div>\r\n\r\n<script type=\"text/javascript\">\r\nfunction initMap2() {\r\n    var map2 = L.map('map2').setView([52.5, 13.4], 11);\r\n\r\n    L.tileLayer('http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {\r\n        attribution: 'Map data &copy; <a href=\"http://openstreetmap.org\">OpenStreetMap</a> contributors',\r\n        maxZoom: 15,\r\n        minZoom: 2\r\n    }).addTo(map2);\r\n\r\n    var geoMarkers = L.layerGroup().addTo(map2);\r\n    var markerIcon = L.icon({\r\n        iconUrl: 'https://openstationmap.org/0.2.0/client/leaflet/images/marker-icon.png',\r\n        iconSize: [24, 32],\r\n    });\r\n\r\n    var el = angular.element($('#map2').parent('.ng-scope'));\r\n    angular.element(el).ready(function() {\r\n        window.pinWatcher = el.scope().compiledScope.$watch('pins', function(pinList, oldValue) {\r\n            geoMarkers.clearLayers();\r\n            angular.forEach(pinList, function(pin) {\r\n                var marker = L.marker([ pin.lat, pin.lon ], {icon: markerIcon})\r\n                  .bindPopup(pin.data)\r\n                  .addTo(geoMarkers);\r\n            });\r\n        })\r\n    });}\r\n\r\nif (window.pinWatcher) {\r\n    // clear existing watcher otherwise we'll have duplicates\r\n    window.pinWatcher();\r\n}\r\n\r\n// ensure we only load the script once, seems to cause issues otherwise\r\nif (window.L) {\r\n    initMap2();\r\n} else {\r\n    console.log('Loading Leaflet library');\r\n    var sc = document.createElement('script');\r\n    sc.type = 'text/javascript';\r\n    sc.src = 'https://cdnjs.cloudflare.com/ajax/libs/leaflet/0.7.5/leaflet.js';\r\n    sc.onload = initMap2;\r\n    sc.onerror = function(err) { alert(err); }\r\n    document.getElementsByTagName('head')[0].appendChild(sc);\r\n}\r\n</script>","dateUpdated":"2018-04-24T18:26:03+0000","config":{"tableHide":false,"editorSetting":{"language":"text","editOnDblClick":true},"colWidth":8,"editorMode":"ace/mode/undefined","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"ANGULAR","data":"<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/leaflet/0.7.5/leaflet.css\" />\r\n<h3>Client-side Integration</h3>\r\n<div id=\"map2\" style=\"height: 600px; width: 100%\"></div>\r\n\r\n<script type=\"text/javascript\">\r\nfunction initMap2() {\r\n    var map2 = L.map('map2').setView([52.5, 13.4], 11);\r\n\r\n    L.tileLayer('http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {\r\n        attribution: 'Map data &copy; <a href=\"http://openstreetmap.org\">OpenStreetMap</a> contributors',\r\n        maxZoom: 15,\r\n        minZoom: 2\r\n    }).addTo(map2);\r\n\r\n    var geoMarkers = L.layerGroup().addTo(map2);\r\n    var markerIcon = L.icon({\r\n        iconUrl: 'https://openstationmap.org/0.2.0/client/leaflet/images/marker-icon.png',\r\n        iconSize: [24, 32],\r\n    });\r\n\r\n    var el = angular.element($('#map2').parent('.ng-scope'));\r\n    angular.element(el).ready(function() {\r\n        window.pinWatcher = el.scope().compiledScope.$watch('pins', function(pinList, oldValue) {\r\n            geoMarkers.clearLayers();\r\n            angular.forEach(pinList, function(pin) {\r\n                var marker = L.marker([ pin.lat, pin.lon ], {icon: markerIcon})\r\n                  .bindPopup(pin.data)\r\n                  .addTo(geoMarkers);\r\n            });\r\n        })\r\n    });}\r\n\r\nif (window.pinWatcher) {\r\n    // clear existing watcher otherwise we'll have duplicates\r\n    window.pinWatcher();\r\n}\r\n\r\n// ensure we only load the script once, seems to cause issues otherwise\r\nif (window.L) {\r\n    initMap2();\r\n} else {\r\n    console.log('Loading Leaflet library');\r\n    var sc = document.createElement('script');\r\n    sc.type = 'text/javascript';\r\n    sc.src = 'https://cdnjs.cloudflare.com/ajax/libs/leaflet/0.7.5/leaflet.js';\r\n    sc.onload = initMap2;\r\n    sc.onerror = function(err) { alert(err); }\r\n    document.getElementsByTagName('head')[0].appendChild(sc);\r\n}\r\n</script>"}]},"apps":[],"jobName":"paragraph_1524594363562_-597672796","id":"20170809-021534_2122057818","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3520"},{"text":"%spark\n","dateUpdated":"2018-04-24T18:26:03+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524594363562_-597672796","id":"20171127-001231_707705103","dateCreated":"2018-04-24T18:26:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3521"}],"name":"GeoWave-GPX-Demo","id":"2DBNPY7JC","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}