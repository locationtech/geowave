#!/bin/bash
#
# Upload datastore jar into HDFS
# Attempt to use a variety of common HDFS root usernames an optional user arg will override
#
# deploy-geowave-to-hdfs.sh [--user HDFS_ROOT_USERNAME]
#

# Test for installed apps required to run this script
dependency_tests() {
    REQUIRED_APPS=('hadoop')

    for app in "${REQUIRED_APPS[@]}"
    do
        type $app >/dev/null 2>&1 || { echo >&2 "$0 needs the $app command to be installed . Aborting."; exit 1; }
    done
}

read_dom () {
    local IFS=\>
    read -d \< ENTITY CONTENT
}

# Sanity check of environment
dependency_tests

# Start detecting the other required settings
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
DATASTORE_USER=$DATASTORE_USER_TOKEN

# Parse any arguments passed to the script
declare -A ARGS
while [ $# -gt 0 ]; do
    case "$1" in
        *) NAME="${1:2}"; shift; ARGS[$NAME]="$1" ;;
    esac
    shift
done

determine_hdfs_user() {
    # Various usernames distros configure to be the one with "root" HDFS permissions
    HADOOP_USERS=('hdfs' 'hadoop' 'cloudera-scm')
    if [ ! -z ${ARGS[user]} ]; then # Use custom user if provided
        HADOOP_USERS=( ${ARGS[user]} )
    fi
    HADOOP_USER=
    for user in "${HADOOP_USERS[@]}"
    do
        getent passwd $user > /dev/null
        if [ $? -eq 0 ] ; then
            HADOOP_USER=$user
            break
        fi
    done

    if [ ! -z $HADOOP_USER ]; then
        echo $HADOOP_USER
    else
        echo >&2 "Cannot determine user account to use for HDFS, tried '${HADOOP_USERS[@]}'. Aborting."
        exit 1
    fi
}

HDFS_USER=$(determine_hdfs_user)

parseVersion() {
echo $(cat "$SCRIPT_DIR/geowave-$DATASTORE_TOKEN-build.properties" | grep "project.version=" | sed -e 's/"//g' -e 's/-SNAPSHOT//g' -e 's/project.version=//g')
}

# Test to see if datastore has been initialized by looking at hdfs contents
determine_$DATASTORE_TOKEN_hdfs_root() {
    DATASTORE_ROOT_DIRS=('/$DATASTORE_TOKEN' '/user/$DATASTORE_TOKEN' '/apps/$DATASTORE_TOKEN')
    ROOT_DIR=
    for dir in "${DATASTORE_ROOT_DIRS[@]}"
    do
        su $HDFS_USER -c "hadoop fs -ls $dir" > /dev/null
        if [ $? -eq 0 ] ; then
            ROOT_DIR=$dir
            break
        fi
    done

    if [ ! -z $ROOT_DIR ]; then
        echo $ROOT_DIR
    else
        echo >&2 "$DATASTORE_TOKEN application directory not found in HDFS, tried '${DATASTORE_ROOT_DIRS[@]}'. Aborting."
        exit 1
    fi
}

# To support concurrent version and vendor installs we're naming the directory that contains the iterator with
# both the vendor and application version so we can support things like 0.8.7-cdh5, 0.8.7-cdh6, 0.8.8-hdp2 etc.
determine_vendor_version() {
    while [ $# -gt 0 ]; do
        ARG="${1:2}"
        KEY="${ARG%%=*}"
        VALUE="${ARG#*=}"
        case "$KEY" in
            "vendor.version") echo "$VALUE" ;;
            *) # Do nothing
        esac
        shift
    done
}
BUILD_ARGS_KEY="project.build.args="
BUILD_ARGS_VAL=$(cat $SCRIPT_DIR/geowave-$DATASTORE_TOKEN-build.properties | grep "$BUILD_ARGS_KEY" | sed -e "s/$BUILD_ARGS_KEY//")
VENDOR_VERSION=$(determine_vendor_version $BUILD_ARGS_VAL)
if [ ! -z $VENDOR_VERSION ]; then
    VENDOR_VERSION="$(parseVersion)-$VENDOR_VERSION"
else
    VENDOR_VERSION="$(parseVersion)"
fi
DATASTORE_LIB_DIR="$(determine_$DATASTORE_TOKEN_hdfs_root)/lib"
GEOWAVE_DATASTORE_HOME=/usr/local/geowave-$VENDOR_VERSION/$DATASTORE_TOKEN

# Check to see if lib directory is already present
su $DATASTORE_USER -c "hadoop fs -ls $DATASTORE_LIB_DIR"
if [ $? -ne 0 ]; then # Try creating
    su $HDFS_USER -c "hadoop fs -mkdir -p $DATASTORE_LIB_DIR"
    if [ $? -ne 0 ]; then
        echo >&2 "Unable to create $DATASTORE_LIB_DIR directory in hdfs. Aborting."; exit 1;
    fi
fi

# Check to see if the library is already present and remove if so (put will not replace)
su $HDFS_USER -c "hadoop fs -ls $DATASTORE_LIB_DIR/geowave-$DATASTORE_TOKEN-$VENDOR_VERSION.jar"
if [ $? -eq 0 ]; then
    su $HDFS_USER -c "hadoop fs -rm $DATASTORE_LIB_DIR/geowave-$DATASTORE_TOKEN-$VENDOR_VERSION.jar"
fi

# Upload library to hdfs
su $HDFS_USER -c "hadoop fs -put $GEOWAVE_DATASTORE_HOME/geowave-$DATASTORE_TOKEN-$VENDOR_VERSION.jar $DATASTORE_LIB_DIR/geowave-$DATASTORE_TOKEN-$VENDOR_VERSION.jar"
if [ $? -ne 0 ]; then
echo >&2 "Unable to upload geowave-$DATASTORE_TOKEN-$VENDOR_VERSION.jar into hdfs. Aborting."; exit 1;
fi

# Also upload the build metadata file for ease of inspection
su $HDFS_USER -c "hadoop fs -ls $DATASTORE_LIB_DIR/geowave-$DATASTORE_TOKEN-build.properties"
if [ $? -eq 0 ]; then
    su $HDFS_USER -c "hadoop fs -rm $DATASTORE_LIB_DIR/geowave-$DATASTORE_TOKEN-build.properties"
fi

su $HDFS_USER -c "hadoop fs -put $GEOWAVE_DATASTORE_HOME/geowave-$DATASTORE_TOKEN-build.properties $DATASTORE_LIB_DIR/geowave-$DATASTORE_TOKEN-build.properties"
if [ $? -ne 0 ]; then
    echo >&2 "Unable to upload geowave-$DATASTORE_TOKEN-build.properties into hdfs. Aborting."; exit 1;
fi

# Set ownership to datastore user
su $HDFS_USER -c "hadoop fs -chown -R $DATASTORE_USER:$DATASTORE_USER $DATASTORE_LIB_DIR"
if [ $? -ne 0 ]; then
    echo >&2 "Unable to change ownership of the $DATASTORE_LIB_DIR directory in hdfs. Aborting."; exit 1;
fi

#Find hbase conf path
if [[ -x "$(command -v hbase)" ]]
    PATHS=$(hbase classpath)
    IFS=':' read -ra CLASSPATHS <<< "$PATHS"

    for i in "${CLASSPATHS[@]}"
    do
      if [[ $i = *"hbase/conf" ]]; then
         CONFPATH=$i
         break
      fi
    done    
fi

GOTELEM=0
# If using Hbase on AWS, scan hbase configs, find configured bucket and copy library over.
if [[ -x "$(command -v aws)" ]] && [ ! -z "$CONFPATH" ] && [[ -e "$CONFPATH/hbase-site.xml" ]]; then

  while read_dom; do
    if [[ -z  "$(echo -e "${CONTENT}" | tr -d '[:space:]')"  ]]; then
      continue;
    fi

    if [[ $ENTITY = "name" ]] && [ $CONTENT = "hbase.rootdir" ]; then
      GOTELEM=1;
      continue
    fi

    if [[ $GOTELEM -eq 1 ]] && [[ $CONTENT = "s3://"* ]]; then
      CONTENT=${CONTENT%/}
      echo -e "s3 cp $GEOWAVE_DATASTORE_HOME/geowave-$DATASTORE_TOKEN-$VENDOR_VERSION.jar $CONTENT/lib/geowave-tools-$VENDOR_VERSION-apache.jar"
      aws s3 cp $GEOWAVE_DATASTORE_HOME/geowave-$DATASTORE_TOKEN-$VENDOR_VERSION.jar $CONTENT/lib/geowave-tools-$VENDOR_VERSION-apache.jar
    fi

    if [ $GOTELEM -eq 1 ]; then
      break
    fi
  done < $CONFPATH/hbase-site.xml
fi
